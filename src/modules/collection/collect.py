"""
collect.py - Naver News Collection Module
ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¥¼ í†µí•´ ë¸Œëœë“œ ê´€ë ¨ ê¸°ì‚¬ ìˆ˜ì§‘
"""

import time
import requests
import pandas as pd
from typing import List, Dict
from pathlib import Path


# ë¸Œëœë“œ ì„¤ì •
OUR_BRANDS = ["ë¡¯ë°í˜¸í…”", "í˜¸í…”ë¡¯ë°", "L7", "ì‹œê·¸ë‹ˆì—˜"]
COMPETITORS = ["ì‹ ë¼í˜¸í…”", "ì¡°ì„ í˜¸í…”"]

NAVER_API_URL = "https://openapi.naver.com/v1/search/news.json"


def fetch_naver(query: str, display: int, start: int, sort: str,
                naver_id: str, naver_secret: str) -> List[Dict]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í˜¸ì¶œ

    Args:
        query: ê²€ìƒ‰ì–´
        display: ê°€ì ¸ì˜¬ ê°œìˆ˜
        start: ì‹œì‘ ì¸ë±ìŠ¤
        sort: ì •ë ¬ ë°©ì‹ (date/sim)
        naver_id: ë„¤ì´ë²„ í´ë¼ì´ì–¸íŠ¸ ID
        naver_secret: ë„¤ì´ë²„ í´ë¼ì´ì–¸íŠ¸ Secret

    Returns:
        ê¸°ì‚¬ ëª©ë¡ (dict ë¦¬ìŠ¤íŠ¸)
    """
    headers = {
        "X-Naver-Client-Id": naver_id,
        "X-Naver-Client-Secret": naver_secret
    }
    params = {
        "query": query,
        "display": display,
        "start": start,
        "sort": sort
    }

    try:
        response = requests.get(NAVER_API_URL, headers=headers, params=params, timeout=10)

        if response.status_code == 401:
            raise RuntimeError("ë„¤ì´ë²„ API ì¸ì¦ ì‹¤íŒ¨ (401). í´ë¼ì´ì–¸íŠ¸ ID/Secretì„ í™•ì¸í•˜ì„¸ìš”.")
        elif response.status_code == 429:
            raise RuntimeError("ë„¤ì´ë²„ API ìš”ì²­ í•œë„ ì´ˆê³¼ (429). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        elif response.status_code >= 500:
            raise RuntimeError(f"ë„¤ì´ë²„ API ì„œë²„ ì˜¤ë¥˜ ({response.status_code})")

        response.raise_for_status()
        data = response.json()
        return data.get("items", [])

    except requests.exceptions.RequestException as e:
        print(f"âš ï¸  '{query}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def fetch_naver_paginated(query: str, display: int, max_pages: int, sort: str,
                          naver_id: str, naver_secret: str, existing_links: set = None) -> List[Dict]:
    """
    í˜ì´ì§€ë„¤ì´ì…˜ì„ í†µí•´ ì—¬ëŸ¬ í˜ì´ì§€ì˜ ê¸°ì‚¬ ìˆ˜ì§‘

    Args:
        query: ê²€ìƒ‰ì–´
        display: í•œ í˜ì´ì§€ë‹¹ ê°€ì ¸ì˜¬ ê°œìˆ˜ (ê¸°ë³¸: 100)
        max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¶Œì¥: 9 for 90% ì¿¼í„° ì•ˆì „ ë§ˆì§„)
        sort: ì •ë ¬ ë°©ì‹ (date/sim)
        naver_id: ë„¤ì´ë²„ í´ë¼ì´ì–¸íŠ¸ ID
        naver_secret: ë„¤ì´ë²„ í´ë¼ì´ì–¸íŠ¸ Secret
        existing_links: ê¸°ì¡´ ë§í¬ set (ì¤‘ë³µ ì²´í¬ìš©)

    Returns:
        ëª¨ë“  í˜ì´ì§€ì˜ ê¸°ì‚¬ ëª©ë¡ (dict ë¦¬ìŠ¤íŠ¸)
    """
    all_items = []
    existing_links = existing_links or set()

    for page in range(1, max_pages + 1):
        start = (page - 1) * display + 1
        print(f"    Page {page}/{max_pages}...", end="", flush=True)

        items = fetch_naver(query, display, start, sort, naver_id, naver_secret)

        if not items:
            print(" (no more articles)")
            break

        # ì¤‘ë³µ ì²´í¬: ê¸°ì¡´ ë§í¬ì™€ ì¤‘ë³µë˜ëŠ” articleì´ ë°œê²¬ë˜ë©´ ì¡°ê¸° ì¢…ë£Œ
        duplicate_found = False
        new_items = []
        for item in items:
            item_link = item.get("link", "")
            if item_link in existing_links:
                duplicate_found = True
                break
            new_items.append(item)
            existing_links.add(item_link)

        all_items.extend(new_items)
        print(f" {len(new_items)} articles", end="")

        if duplicate_found:
            print(" (ì¤‘ë³µ ë°œê²¬, ìˆ˜ì§‘ ì¤‘ë‹¨)")
            break

        print()

        # í˜ì´ì§€ ê°„ ìš”ì²­ ì‚¬ì´ì— ë”œë ˆì´ (Rate limiting)
        if page < max_pages:
            time.sleep(0.2)

    return all_items


def collect_all_news(brands: List[str], competitors: List[str],
                     display: int, max_pages: int, sort: str,
                     naver_id: str, naver_secret: str,
                     raw_csv_path: str = None) -> pd.DataFrame:
    """
    ëª¨ë“  ë¸Œëœë“œì™€ ê²½ìŸì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘

    Args:
        raw_csv_path: raw.csv íŒŒì¼ ê²½ë¡œ (ì¤‘ë³µ ì²´í¬ìš©, ì„ íƒì‚¬í•­)

    Returns:
        DataFrame with columns: query, group, title, description, pubDate, originallink, link
    """
    all_rows = []

    # ê¸°ì¡´ ë§í¬ ë¡œë“œ (raw.csvì—ì„œ)
    existing_links = set()
    if raw_csv_path and Path(raw_csv_path).exists():
        try:
            df_existing = pd.read_csv(raw_csv_path, encoding='utf-8-sig')
            if 'link' in df_existing.columns:
                existing_links = set(df_existing['link'].dropna().tolist())
                print(f"ğŸ“‚ ê¸°ì¡´ raw.csvì—ì„œ {len(existing_links)}ê°œ ë§í¬ ë¡œë“œ (ì¤‘ë³µ ì²´í¬ìš©)\n")
        except Exception as e:
            print(f"âš ï¸  raw.csv ë¡œë“œ ì‹¤íŒ¨: {e}\n")

    # ìš°ë¦¬ ë¸Œëœë“œ ìˆ˜ì§‘
    print(f"ğŸ“° ìš°ë¦¬ ë¸Œëœë“œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ (ìµœëŒ€ {max_pages} í˜ì´ì§€)...")
    for query in brands:
        print(f"  â†’ {query}")
        items = fetch_naver_paginated(query, display, max_pages, sort, naver_id, naver_secret, existing_links)
        for item in items:
            all_rows.append({
                "query": query,
                "group": "OUR",
                "title": item.get("title", ""),
                "description": item.get("description", ""),
                "pubDate": item.get("pubDate", ""),
                "originallink": item.get("originallink", ""),
                "link": item.get("link", "")
            })
        time.sleep(0.1)  # Rate limit ë°©ì§€

    # ê²½ìŸì‚¬ ìˆ˜ì§‘
    print(f"\nğŸ“° ê²½ìŸì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ (ìµœëŒ€ {max_pages} í˜ì´ì§€)...")
    for query in competitors:
        print(f"  â†’ {query}")
        items = fetch_naver_paginated(query, display, max_pages, sort, naver_id, naver_secret, existing_links)
        for item in items:
            all_rows.append({
                "query": query,
                "group": "COMPETITOR",
                "title": item.get("title", ""),
                "description": item.get("description", ""),
                "pubDate": item.get("pubDate", ""),
                "originallink": item.get("originallink", ""),
                "link": item.get("link", "")
            })
        time.sleep(0.1)

    df = pd.DataFrame(all_rows)
    print(f"\nâœ… ì´ {len(df)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
    return df
