"""
media_classify.py - Media Outlet Classification Module
ì–¸ë¡ ì‚¬ ë¶„ë¥˜ ë° ë§¤ì²´ ì •ë³´ ì¶”ê°€
"""

import json
import uuid
from typing import Dict, List, Optional
from urllib.parse import urlparse
from pathlib import Path
import pandas as pd

from src.utils.openai_client import (
    OPENAI_API_URL,
    set_error_callback,
    load_api_models,
    call_openai_with_retry,
    extract_response_text,
    notify_error,
)
from src.utils.sheets_helpers import get_or_create_worksheet


def extract_domain_safe(url: str) -> str:
    """
    URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ (www. ì œê±°, ì—ëŸ¬ ì•ˆì „)

    Args:
        url: ê¸°ì‚¬ URL

    Returns:
        ë„ë©”ì¸ (ì˜ˆ: "chosun.com") ë˜ëŠ” ë¹ˆ ë¬¸ìì—´

    Examples:
        https://www.chosun.com/article/123 â†’ chosun.com
        https://woman.chosun.com/article/456 â†’ woman.chosun.com
        invalid-url â†’ ""
    """
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.replace('www.', '')
        return domain if domain else ""
    except Exception:
        return ""


def load_media_directory(spreadsheet=None) -> Dict[str, Dict]:
    """
    media_directory ë¡œë“œ (Google Sheetsë§Œ ì‚¬ìš©)

    Args:
        spreadsheet: gspread Spreadsheet ê°ì²´ (ì„ íƒì‚¬í•­)

    Returns:
        {domain: {"media_name": ..., "media_group": ..., "media_type": ...}} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    if spreadsheet:
        try:
            worksheet = spreadsheet.worksheet("media_directory")
            existing_data = worksheet.get_all_records()

            if existing_data:
                media_dir = {}
                for row in existing_data:
                    domain = row.get("domain", "").strip()
                    if domain:
                        media_dir[domain] = {
                            "media_name": row.get("media_name", ""),
                            "media_group": row.get("media_group", ""),
                            "media_type": row.get("media_type", "")
                        }
                print(f"ğŸ“‚ media_directory (Google Sheets): {len(media_dir)}ê°œ ë„ë©”ì¸ ë¡œë“œ")
                return media_dir
        except Exception as e:
            print(f"  âš ï¸  Google Sheets media_directory ë¡œë“œ ì‹¤íŒ¨: {e}")

    print("  â„¹ï¸  media_directoryê°€ ì—†ìŠµë‹ˆë‹¤. ì‹ ê·œ ìƒì„±í•©ë‹ˆë‹¤.")
    return {}


def classify_media_outlets_batch(
    domains: List[str],
    openai_key: str,
    max_retries: int = 5,
) -> Dict[str, Dict]:
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ë¡ ì‚¬ ì •ë³´ ë¶„ë¥˜ (ë°°ì¹˜ ì²˜ë¦¬)

    Args:
        domains: ë¶„ë¥˜í•  ë„ë©”ì¸ ëª©ë¡
        openai_key: OpenAI API í‚¤
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

    Returns:
        {domain: {"media_name": ..., "media_group": ..., "media_type": ...}} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    if not domains:
        return {}

    # ë„ë©”ì¸ ëª©ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    domain_list = "\n".join(domains)

    prompt = f"""í•œêµ­ ì–¸ë¡ ì‚¬ ì •ë³´ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.

ë„ë©”ì¸:
{domain_list}

JSONë§Œ ë°˜í™˜:
{{"classifications":[{{"domain":"example.com","media_name":"ì˜ˆì‹œì–¸ë¡ ","media_group":"ì˜ˆì‹œê·¸ë£¹","media_type":"ì¢…í•©ì§€"}}]}}

ë¶„ë¥˜:
- ì¢…í•©ì§€/ê²½ì œì§€/ITì „ë¬¸ì§€/ë°©ì†¡ì‚¬/í†µì‹ ì‚¬/ì¸í„°ë„·ì‹ ë¬¸/ê¸°íƒ€
- groupì€ ëª¨ë¥´ë©´ media_name ë™ì¼
- JSONë§Œ"""

    headers = {
        "Authorization": f"Bearer {openai_key}",
        "Content-Type": "application/json"
    }

    # api_models.yamlì—ì„œ ëª¨ë¸ ë¡œë“œ
    api_models = load_api_models()
    model = api_models.get("media_classification", "gpt-5-nano")

    data = {
        "model": model,
        "input": [
            {"role": "user", "content": [{"type": "input_text", "text": prompt}]}
        ],
        "text": {
            "format": {
                "type": "json_schema",
                "name": "media_classification_batch",
                "strict": True,
                "schema": {
                    "type": "object",
                    "additionalProperties": False,
                    "required": ["classifications"],
                    "properties": {
                        "classifications": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "additionalProperties": False,
                                "required": ["domain", "media_name", "media_group", "media_type"],
                                "properties": {
                                    "domain": {"type": "string"},
                                    "media_name": {"type": "string"},
                                    "media_group": {"type": "string"},
                                    "media_type": {
                                        "type": "string",
                                        "enum": ["ì¢…í•©ì§€", "ê²½ì œì§€", "ITì „ë¬¸ì§€", "ë°©ì†¡ì‚¬", "í†µì‹ ì‚¬", "ì¸í„°ë„·ì‹ ë¬¸", "ê¸°íƒ€"]
                                    }
                                }
                            }
                        }
                    }
                }
            }
        },
        "max_output_tokens": min(len(domains) * 100, 8000)  # ìµœì†Œ 100í† í°/ë„ë©”ì¸, ìµœëŒ€ 8000
    }

    request_id = uuid.uuid4().hex[:8]
    print(f"  ğŸ¤– OpenAI ë¶„ë¥˜: {len(domains)}ê°œ ì‹ ê·œ ë„ë©”ì¸", end="", flush=True)

    response = call_openai_with_retry(
        OPENAI_API_URL, headers, data,
        max_retries=max_retries, request_id=request_id, label="ì–¸ë¡ ì‚¬ë¶„ë¥˜"
    )

    if response is None:
        print(" (ì¬ì‹œë„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©)")
        return _fallback_classification(domains)

    result = response.json()
    content = extract_response_text(result)

    try:
        parsed = json.loads(content)
        classifications = parsed.get("classifications", [])
    except json.JSONDecodeError as e:
        print(f" (JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)[:50]}, ê¸°ë³¸ê°’ ì‚¬ìš©)")
        notify_error(
            "OpenAI ì–¸ë¡ ì‚¬ ë¶„ë¥˜ íŒŒì‹± ì‹¤íŒ¨",
            {"request_id": request_id, "error": f"{type(e).__name__}: {e}"}
        )
        return _fallback_classification(domains)

    # ë„ë©”ì¸ ê¸°ì¤€ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    media_info = {}
    for item in classifications:
        domain = item.get("domain", "")
        if domain:
            media_info[domain] = {
                "media_name": item.get("media_name", domain),
                "media_group": item.get("media_group", domain),
                "media_type": item.get("media_type", "ê¸°íƒ€")
            }

    print(f" âœ…")
    return media_info


def _fallback_classification(domains: List[str]) -> Dict[str, Dict]:
    """
    OpenAI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©

    Args:
        domains: ë„ë©”ì¸ ëª©ë¡

    Returns:
        {domain: {media_name: domain, media_group: domain, media_type: "ê¸°íƒ€"}}
    """
    return {
        domain: {
            "media_name": domain,
            "media_group": domain,
            "media_type": "ê¸°íƒ€"
        }
        for domain in domains
    }


def update_media_directory(spreadsheet=None, new_entries: Dict[str, Dict] = None) -> None:
    """
    media_directory ì—…ë°ì´íŠ¸ (Google Sheetsë§Œ)

    Args:
        spreadsheet: gspread Spreadsheet ê°ì²´ (ì„ íƒì‚¬í•­)
        new_entries: {domain: {"media_name": ..., "media_group": ..., "media_type": ...}}
    """
    if not new_entries:
        return

    if spreadsheet:
        try:
            worksheet = get_or_create_worksheet(spreadsheet, "media_directory", rows=1, cols=4)
            existing_rows = worksheet.row_values(1)
            if not existing_rows:
                worksheet.append_row(["domain", "media_name", "media_group", "media_type"])

            rows_to_add = [
                [domain, info.get("media_name", ""), info.get("media_group", ""), info.get("media_type", "")]
                for domain, info in new_entries.items()
            ]

            if rows_to_add:
                worksheet.append_rows(rows_to_add)

            print(f"âœ… media_directory (Google Sheets): {len(new_entries)}ê°œ ì‹ ê·œ ë„ë©”ì¸ ì¶”ê°€")
        except Exception as e:
            print(f"âš ï¸  Google Sheets ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")


def add_media_columns(
    df: pd.DataFrame,
    spreadsheet=None,
    openai_key: str = None,
):
    """
    DataFrameì— ì–¸ë¡ ì‚¬ ì •ë³´ ì»¬ëŸ¼ ì¶”ê°€

    Args:
        df: ì²˜ë¦¬ëœ DataFrame (originallink ì»¬ëŸ¼ í•„ìš”)
        spreadsheet: gspread Spreadsheet ê°ì²´ (ì„ íƒì‚¬í•­)
        openai_key: OpenAI API í‚¤ (ì„ íƒì‚¬í•­)

    Returns:
        (df, media_stats) íŠœí”Œ:
        - df: 4ê°œì˜ ìƒˆë¡œìš´ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
        - media_stats: {"media_domains_total", "media_domains_new", "media_domains_cached"}
    """
    empty_stats = {"media_domains_total": 0, "media_domains_new": 0, "media_domains_cached": 0}

    print("ğŸ¢ ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€ ì¤‘...")
    df = df.copy()

    # ì»¬ëŸ¼ ì´ˆê¸°í™”
    df["media_domain"] = ""
    df["media_name"] = ""
    df["media_group"] = ""
    df["media_type"] = ""

    # originallink ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¡°ê¸° ë°˜í™˜
    if "originallink" not in df.columns:
        print("  âš ï¸  originallink ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return df, empty_stats

    try:
        # ë„ë©”ì¸ ì¶”ì¶œ
        df["media_domain"] = df["originallink"].apply(extract_domain_safe)

        # ê³ ìœ í•œ ë„ë©”ì¸ ëª©ë¡
        unique_domains = df[df["media_domain"] != ""]["media_domain"].unique()
        unique_domains = [d for d in unique_domains if d]

        if not unique_domains:
            print("  âš ï¸  ì¶”ì¶œëœ ë„ë©”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return df, empty_stats

        # media_directory ë¡œë“œ (Google Sheets)
        existing_media = load_media_directory(spreadsheet=spreadsheet)
        new_domains = [d for d in unique_domains if d not in existing_media]

        # ì‹ ê·œ ë„ë©”ì¸ ë¶„ë¥˜ (OpenAI) - ë°°ì¹˜ ì²˜ë¦¬ (100ê°œì”©)
        if new_domains and openai_key:
            new_media = {}
            for i in range(0, len(new_domains), 100):
                batch = new_domains[i:i+100]
                batch_result = classify_media_outlets_batch(batch, openai_key)
                new_media.update(batch_result)

            existing_media.update(new_media)

            # media_directory ì—…ë°ì´íŠ¸ (Sheetsë§Œ)
            update_media_directory(spreadsheet=spreadsheet, new_entries=new_media)

        # DataFrameì— ì •ë³´ ì¶”ê°€
        for idx, row in df.iterrows():
            domain = row["media_domain"]
            if domain in existing_media:
                info = existing_media[domain]
                df.at[idx, "media_name"] = info.get("media_name", "")
                df.at[idx, "media_group"] = info.get("media_group", "")
                df.at[idx, "media_type"] = info.get("media_type", "")

        # í†µê³„
        has_info = (df["media_name"] != "").sum()
        print(f"âœ… ì™„ë£Œ: {len(df)}ê°œ ê¸°ì‚¬ì— ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€")
        print(f"  - ê¸°ì¡´ ë””ë ‰í† ë¦¬: {len(existing_media) - len(new_domains)}ê°œ")
        if new_domains:
            print(f"  - ì‹ ê·œ ë¶„ë¥˜: {len(new_domains)}ê°œ")

        media_stats = {
            "media_domains_total": len(unique_domains),
            "media_domains_new": len(new_domains),
            "media_domains_cached": len(unique_domains) - len(new_domains),
        }
        return df, media_stats

    except Exception as e:
        print(f"âš ï¸  ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
        return df, empty_stats
