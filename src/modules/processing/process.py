"""
process.py - Data Processing Module
ë°ì´í„° ì •ê·œí™”, ì¤‘ë³µ ì œê±°, CSV ì €ì¥
"""

import re
import hashlib
from html import unescape
from datetime import datetime
from pathlib import Path
from typing import Optional
import pandas as pd

# ë³´ë„ìë£Œ ê²€ì¶œ/ìš”ì•½ì€ ë³„ë„ ëª¨ë“ˆë¡œ ë¶„ë¦¬
from .press_release_detector import detect_similar_articles, summarize_press_release_groups


def strip_html(text: str) -> str:
    """HTML íƒœê·¸ ì œê±° ë° ì—”í‹°í‹° ë””ì½”ë”©"""
    if not text:
        return ""
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', '', text)
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    text = unescape(text)
    return text.strip()


def parse_pubdate(pubdate_str: str) -> Optional[str]:
    """
    ë„¤ì´ë²„ pubDateë¥¼ ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    ì˜ˆ: 'Mon, 03 Feb 2026 10:30:00 +0900' â†’ '2026-02-03T10:30:00+09:00'
    """
    if not pubdate_str:
        return None
    
    try:
        dt = datetime.strptime(pubdate_str, "%a, %d %b %Y %H:%M:%S %z")
        return dt.isoformat()
    except Exception as e:
        print(f"âš ï¸  ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ '{pubdate_str}': {e}")
        return None


def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    """
    ë°ì´í„° ì •ê·œí™”
    - HTML íƒœê·¸ ì œê±°
    - ë‚ ì§œ íŒŒì‹±
    - article_id (ì˜êµ¬ ì‹ë³„ì) ì¶”ê°€
    - article_no (ìˆœì°¨ ë²ˆí˜¸) ì¶”ê°€
    """
    print("ğŸ”§ ë°ì´í„° ì •ê·œí™” ì¤‘...")
    df = df.copy()

    # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ strip_html ì ìš©
    df["title"] = df["title"].fillna("").apply(strip_html)
    df["description"] = df["description"].fillna("").apply(strip_html)
    df["pub_datetime"] = df["pubDate"].fillna("").apply(parse_pubdate)

    # article_id: link ê¸°ë°˜ MD5 í•´ì‹œ (ì˜êµ¬ ì‹ë³„ì, ì‹œìŠ¤í…œìš©)
    df["article_id"] = df["link"].fillna("").apply(
        lambda x: hashlib.md5(str(x).encode()).hexdigest()[:12] if x else ""
    )

    # article_no: ìˆœì°¨ ë²ˆí˜¸ (ì‚¬ëŒì´ ì½ëŠ” ë²ˆí˜¸, ê²€í† ìš©)
    df["article_no"] = range(1, len(df) + 1)

    print(f"âœ… {len(df)}ê°œ ê¸°ì‚¬ ì •ê·œí™” ì™„ë£Œ (article_id, article_no ì¶”ê°€)")
    return df


def dedupe_df(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì¤‘ë³µ ì œê±° (query ë³‘í•© í¬í•¨)
    - originallink ë˜ëŠ” linkë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
    - ìµœì‹  ê¸°ì‚¬ë§Œ ìœ ì§€í•˜ë˜, queryëŠ” íŒŒì´í”„(|)ë¡œ ë³‘í•©
    - ì˜ˆ: "ë¡¯ë°í˜¸í…”|í˜¸í…”ë¡¯ë°" (ë³µìˆ˜ ë¸Œëœë“œì—ì„œ ìˆ˜ì§‘ëœ ê²½ìš°)
    """
    print("ğŸ”§ ì¤‘ë³µ ê¸°ì‚¬ ì œê±° ì¤‘...")
    df = df.copy()

    # Primary key ìƒì„±
    df["pk"] = df["originallink"].where(df["originallink"].str.strip() != "", df["link"])

    # ë‚ ì§œ ê¸°ì¤€ ì •ë ¬ (ìµœì‹  â†’ ì˜¤ë˜ëœ)
    df["pub_datetime_sort"] = pd.to_datetime(df["pub_datetime"], errors="coerce")
    df = df.sort_values("pub_datetime_sort", ascending=False, na_position="last")

    # query ë³‘í•© (ê°™ì€ pkì˜ queryë“¤ì„ íŒŒì´í”„ë¡œ êµ¬ë¶„)
    query_merged = df.groupby("pk")["query"].apply(
        lambda x: "|".join(sorted(set(x.dropna().astype(str))))
    ).to_dict()

    # query ì»¬ëŸ¼ ì—…ë°ì´íŠ¸
    df["query"] = df["pk"].map(query_merged)

    # ì¤‘ë³µ ì œê±° (ìµœì‹  ê²ƒë§Œ ìœ ì§€)
    original_count = len(df)
    df_deduped = df.drop_duplicates(subset=["pk"], keep="first")

    # ë³µìˆ˜ ë¸Œëœë“œ ìˆ˜ì§‘ í†µê³„
    multi_brand_count = sum(1 for q in df_deduped["query"] if "|" in str(q))

    # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
    df_deduped = df_deduped.drop(columns=["pk", "pub_datetime_sort"])

    removed = original_count - len(df_deduped)
    print(f"âœ… ì¤‘ë³µ {removed}ê°œ ì œê±°, {len(df_deduped)}ê°œ ê¸°ì‚¬ ìœ ì§€")
    if multi_brand_count > 0:
        print(f"   ğŸ“Œ ë³µìˆ˜ ë¸Œëœë“œ ìˆ˜ì§‘: {multi_brand_count}ê°œ ê¸°ì‚¬ (query íŒŒì´í”„(|) êµ¬ë¶„)")
    return df_deduped.reset_index(drop=True)


def enrich_with_media_info(
    df: pd.DataFrame,
    spreadsheet=None,
    openai_key: str = None,
    csv_path: Path = None
) -> pd.DataFrame:
    """
    DataFrameì— ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€ (wrapper for media_classify.add_media_columns)

    Args:
        df: ì²˜ë¦¬ëœ DataFrame
        spreadsheet: gspread Spreadsheet ê°ì²´ (ì„ íƒì‚¬í•­)
        openai_key: OpenAI API í‚¤ (ì„ íƒì‚¬í•­)
        csv_path: media_directory CSV ê²½ë¡œ (ì„ íƒì‚¬í•­)

    Returns:
        ì–¸ë¡ ì‚¬ ì •ë³´ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
    """
    try:
        from src.modules.processing.media_classify import add_media_columns
        return add_media_columns(df, spreadsheet, openai_key, csv_path)
    except ImportError:
        print("âš ï¸  media_classify ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return df
    except Exception as e:
        print(f"âš ï¸  ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
        return df


# detect_similar_articles í•¨ìˆ˜ëŠ” similarity_detector.pyë¡œ ì´ë™
# ìœ„ì—ì„œ importë¨


def save_csv(df: pd.DataFrame, filepath: Path) -> None:
    """
    CSV íŒŒì¼ë¡œ ì €ì¥ (UTF-8 BOM ì¸ì½”ë”©, ëª¨ë“  í•„ë“œ quoting)
    BOM ë¬¸ì(\ufeff) ë° invisible ë¬¸ìë¥¼ ë°ì´í„°ì—ì„œ ì œê±°
    """
    import csv
    import re
    try:
        filepath.parent.mkdir(parents=True, exist_ok=True)

        # ëª¨ë“  BOM ë° invisible ë¬¸ì ì œê±° (ë°ì´í„° ë‚´ë¶€)
        df_clean = df.copy()

        # ì •ê·œì‹ìœ¼ë¡œ ëª¨ë“  invisible/ì œì–´ ë¬¸ì ì¼ê´„ ì œê±°
        invisible_pattern = re.compile(
            r'[\ufeff\ufffe'
            r'\u200b-\u200f'
            r'\u2028-\u202f'
            r'\u2060\u180e'
            r'\u00a0\u3000\u00ad'
            r'\ufff9-\ufffc'
            r'\x00-\x08\x0b\x0c\x0e-\x1f'
            r'\x7f-\x9f]'
        )

        for col in df_clean.columns:
            if df_clean[col].dtype == 'object':
                df_clean[col] = df_clean[col].apply(
                    lambda x: invisible_pattern.sub('', str(x)).strip()
                    if pd.notna(x) and x != '' else x
                )

        df_clean.to_csv(filepath, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_NONNUMERIC)
        print(f"ğŸ’¾ ì €ì¥: {filepath}")
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨ ({filepath}): {e}")
        print("  â†’ ë””ìŠ¤í¬ ê³µê°„ ë˜ëŠ” ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")


# summarize_press_release_groups() í•¨ìˆ˜ëŠ” press_release_detector.pyë¡œ ì´ë™
# ìœ„ì—ì„œ importë¨


