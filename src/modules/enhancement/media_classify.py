"""
media_classify.py - Media Outlet Classification Module
ì–¸ë¡ ì‚¬ ë¶„ë¥˜ ë° ë§¤ì²´ ì •ë³´ ì¶”ê°€
"""

import json
import time
import requests
from typing import Dict, List, Optional
from urllib.parse import urlparse
import pandas as pd


def extract_domain_safe(url: str) -> str:
    """
    URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ (www. ì œê±°, ì—ëŸ¬ ì•ˆì „)

    Args:
        url: ê¸°ì‚¬ URL

    Returns:
        ë„ë©”ì¸ (ì˜ˆ: "chosun.com") ë˜ëŠ” ë¹ˆ ë¬¸ìì—´

    Examples:
        https://www.chosun.com/article/123 â†’ chosun.com
        https://woman.chosun.com/article/456 â†’ woman.chosun.com
        invalid-url â†’ ""
    """
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.replace('www.', '')
        return domain if domain else ""
    except Exception:
        return ""


def load_media_directory(spreadsheet) -> Dict[str, Dict]:
    """
    Google Sheetsì—ì„œ media_directory ì‹œíŠ¸ ë¡œë“œ

    Args:
        spreadsheet: gspread Spreadsheet ê°ì²´

    Returns:
        {domain: {"media_name": ..., "media_group": ..., "media_type": ...}} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # ì›Œí¬ì‹œíŠ¸ ì„ íƒ (ì—†ìœ¼ë©´ ë¹ˆ dict ë°˜í™˜)
        try:
            worksheet = spreadsheet.worksheet("media_directory")
        except:
            print("  â„¹ï¸  'media_directory' ì›Œí¬ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹ ê·œ ìƒì„±í•©ë‹ˆë‹¤.")
            return {}

        # ëª¨ë“  ë°ì´í„° ì½ê¸°
        existing_data = worksheet.get_all_records()

        if not existing_data:
            print("  â„¹ï¸  'media_directory' ì›Œí¬ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return {}

        # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        media_dir = {}
        for row in existing_data:
            domain = row.get("domain", "").strip()
            if domain:
                media_dir[domain] = {
                    "media_name": row.get("media_name", ""),
                    "media_group": row.get("media_group", ""),
                    "media_type": row.get("media_type", "")
                }

        print(f"ğŸ“‚ media_directory: {len(media_dir)}ê°œ ë„ë©”ì¸ ë¡œë“œ")
        return media_dir

    except Exception as e:
        print(f"âš ï¸  media_directory ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def classify_media_outlets_batch(
    domains: List[str],
    openai_key: str,
    retry: bool = True
) -> Dict[str, Dict]:
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ë¡ ì‚¬ ì •ë³´ ë¶„ë¥˜ (ë°°ì¹˜ ì²˜ë¦¬)

    Args:
        domains: ë¶„ë¥˜í•  ë„ë©”ì¸ ëª©ë¡
        openai_key: OpenAI API í‚¤
        retry: ì¬ì‹œë„ ì—¬ë¶€

    Returns:
        {domain: {"media_name": ..., "media_group": ..., "media_type": ...}} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    if not domains:
        return {}

    # ë„ë©”ì¸ ëª©ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    domain_list = "\n".join(domains)

    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì–¸ë¡ ì‚¬ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê° ë„ë©”ì¸ì˜ ì–¸ë¡ ì‚¬ ì •ë³´ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.

ë„ë©”ì¸ ëª©ë¡:
{domain_list}

JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”:
[
  {{
    "domain": "chosun.com",
    "media_name": "ì¡°ì„ ì¼ë³´",
    "media_group": "ì¡°ì„ ë¯¸ë””ì–´ê·¸ë£¹",
    "media_type": "ì¢…í•©ì§€"
  }},
  ...
]

media_type ë¶„ë¥˜ ê¸°ì¤€:
- ì¢…í•©ì§€: ì¡°ì„ ì¼ë³´, ì¤‘ì•™ì¼ë³´, ë™ì•„ì¼ë³´ ë“± ì¼ë°˜ ì¢…í•© ì¼ê°„ì§€
- ê²½ì œì§€: í•œêµ­ê²½ì œ, ë§¤ì¼ê²½ì œ, ì„œìš¸ê²½ì œ ë“± ê²½ì œ ì „ë¬¸ì§€
- ITì „ë¬¸ì§€: ë¸”ë¡œí„°, ì „ìì‹ ë¬¸, ë””ì§€í„¸íƒ€ì„ìŠ¤ ë“±
- ë°©ì†¡ì‚¬: KBS, MBC, SBS, JTBC ë“±
- í†µì‹ ì‚¬: ì—°í•©ë‰´ìŠ¤, ë‰´ì‹œìŠ¤, ë‰´ìŠ¤1 ë“±
- ì¸í„°ë„·ì‹ ë¬¸: ì˜¤ë§ˆì´ë‰´ìŠ¤, í”„ë ˆì‹œì•ˆ, ë¯¸ë””ì–´ì˜¤ëŠ˜ ë“± ì˜¨ë¼ì¸ ì „ìš©
- ê¸°íƒ€: ìœ„ ë¶„ë¥˜ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš°

media_group ê·œì¹™:
- ì•Œë ¤ì§„ ê·¸ë£¹ì´ ìˆìœ¼ë©´ ê¸°ì¬ (ì˜ˆ: ì¡°ì„ ë¯¸ë””ì–´ê·¸ë£¹, ì¤‘ì•™ì¼ë³´ê·¸ë£¹)
- ë…ë¦½ ì–¸ë¡ ì‚¬ëŠ” media_nameê³¼ ë™ì¼í•˜ê²Œ ê¸°ì¬
- ë¶ˆëª…í™•í•˜ë©´ media_nameê³¼ ë™ì¼í•˜ê²Œ ê¸°ì¬

JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    headers = {
        "Authorization": f"Bearer {openai_key}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2,
        "max_tokens": len(domains) * 80
    }

    try:
        print(f"  ğŸ¤– OpenAI ë¶„ë¥˜: {len(domains)}ê°œ ì‹ ê·œ ë„ë©”ì¸", end="", flush=True)
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=60
        )

        if response.status_code == 429:  # Rate limit
            if retry:
                print(" (Rate limit, 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„)")
                time.sleep(5)
                return classify_media_outlets_batch(domains, openai_key, retry=False)
            else:
                print(" (Rate limit ì´ˆê³¼, ê¸°ë³¸ê°’ ì‚¬ìš©)")
                return _fallback_classification(domains)

        if response.status_code != 200:
            print(f" (API ì˜¤ë¥˜ {response.status_code}, ê¸°ë³¸ê°’ ì‚¬ìš©)")
            return _fallback_classification(domains)

        result = response.json()
        content = result.get("choices", [{}])[0].get("message", {}).get("content", "")

        # JSON ì¶”ì¶œ
        try:
            classifications = json.loads(content)
        except json.JSONDecodeError:
            if retry:
                print(" (JSON íŒŒì‹± ì‹¤íŒ¨, 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„)")
                time.sleep(2)
                return classify_media_outlets_batch(domains, openai_key, retry=False)
            else:
                print(" (JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©)")
                return _fallback_classification(domains)

        # ë„ë©”ì¸ ê¸°ì¤€ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        media_info = {}
        for item in classifications:
            domain = item.get("domain", "")
            if domain:
                media_info[domain] = {
                    "media_name": item.get("media_name", domain),
                    "media_group": item.get("media_group", domain),
                    "media_type": item.get("media_type", "ê¸°íƒ€")
                }

        print(f" âœ…")
        return media_info

    except requests.exceptions.Timeout:
        print(" (Timeout, ê¸°ë³¸ê°’ ì‚¬ìš©)")
        return _fallback_classification(domains)
    except Exception as e:
        print(f" (ì˜¤ë¥˜: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©)")
        return _fallback_classification(domains)


def _fallback_classification(domains: List[str]) -> Dict[str, Dict]:
    """
    OpenAI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©

    Args:
        domains: ë„ë©”ì¸ ëª©ë¡

    Returns:
        {domain: {media_name: domain, media_group: domain, media_type: "ê¸°íƒ€"}}
    """
    return {
        domain: {
            "media_name": domain,
            "media_group": domain,
            "media_type": "ê¸°íƒ€"
        }
        for domain in domains
    }


def update_media_directory(spreadsheet, new_entries: Dict[str, Dict]) -> None:
    """
    Google Sheetsì˜ media_directoryì— ì‹ ê·œ ë„ë©”ì¸ ì¶”ê°€

    Args:
        spreadsheet: gspread Spreadsheet ê°ì²´
        new_entries: {domain: {"media_name": ..., "media_group": ..., "media_type": ...}}
    """
    if not new_entries:
        return

    try:
        # ì›Œí¬ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
        try:
            worksheet = spreadsheet.worksheet("media_directory")
        except:
            worksheet = spreadsheet.add_worksheet(title="media_directory", rows=1, cols=4)
            # í—¤ë” ì¶”ê°€
            worksheet.append_row(["domain", "media_name", "media_group", "media_type"])

        # ì‹ ê·œ í•­ëª© ì¶”ê°€
        for domain, info in new_entries.items():
            row = [
                domain,
                info.get("media_name", ""),
                info.get("media_group", ""),
                info.get("media_type", "")
            ]
            worksheet.append_row(row)

        print(f"âœ… media_directory: {len(new_entries)}ê°œ ì‹ ê·œ ë„ë©”ì¸ ì¶”ê°€")

    except Exception as e:
        print(f"âš ï¸  media_directory ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        print("  â†’ Google Sheets ì—…ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.")


def add_media_columns(
    df: pd.DataFrame,
    spreadsheet=None,
    openai_key: str = None
) -> pd.DataFrame:
    """
    DataFrameì— ì–¸ë¡ ì‚¬ ì •ë³´ ì»¬ëŸ¼ ì¶”ê°€

    Args:
        df: ì²˜ë¦¬ëœ DataFrame (originallink ì»¬ëŸ¼ í•„ìš”)
        spreadsheet: gspread Spreadsheet ê°ì²´ (ì„ íƒì‚¬í•­)
        openai_key: OpenAI API í‚¤ (ì„ íƒì‚¬í•­)

    Returns:
        4ê°œì˜ ìƒˆë¡œìš´ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame:
        - media_domain: ì¶”ì¶œëœ ë„ë©”ì¸
        - media_name: ì–¸ë¡ ì‚¬ëª…
        - media_group: ì–¸ë¡ ì‚¬ ê·¸ë£¹
        - media_type: ë§¤ì²´ ë¶„ë¥˜
    """
    print("ğŸ¢ ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€ ì¤‘...")
    df = df.copy()

    # ì»¬ëŸ¼ ì´ˆê¸°í™”
    df["media_domain"] = ""
    df["media_name"] = ""
    df["media_group"] = ""
    df["media_type"] = ""

    # originallink ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¡°ê¸° ë°˜í™˜
    if "originallink" not in df.columns:
        print("  âš ï¸  originallink ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return df

    try:
        # ë„ë©”ì¸ ì¶”ì¶œ
        df["media_domain"] = df["originallink"].apply(extract_domain_safe)

        # ê³ ìœ í•œ ë„ë©”ì¸ ëª©ë¡
        unique_domains = df[df["media_domain"] != ""]["media_domain"].unique()
        unique_domains = [d for d in unique_domains if d]

        if not unique_domains:
            print("  âš ï¸  ì¶”ì¶œëœ ë„ë©”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return df

        # media_directory ë¡œë“œ (Sheets ì—°ê²° ê°€ëŠ¥í•œ ê²½ìš°)
        existing_media = {}
        new_domains = []

        if spreadsheet:
            existing_media = load_media_directory(spreadsheet)
            new_domains = [d for d in unique_domains if d not in existing_media]
        else:
            new_domains = list(unique_domains)

        # ì‹ ê·œ ë„ë©”ì¸ ë¶„ë¥˜ (OpenAI)
        if new_domains and openai_key:
            new_media = classify_media_outlets_batch(new_domains, openai_key)
            existing_media.update(new_media)

            # media_directory ì—…ë°ì´íŠ¸ (Sheets)
            if spreadsheet:
                update_media_directory(spreadsheet, new_media)

        # DataFrameì— ì •ë³´ ì¶”ê°€
        for idx, row in df.iterrows():
            domain = row["media_domain"]
            if domain in existing_media:
                info = existing_media[domain]
                df.at[idx, "media_name"] = info.get("media_name", "")
                df.at[idx, "media_group"] = info.get("media_group", "")
                df.at[idx, "media_type"] = info.get("media_type", "")

        # í†µê³„
        has_info = (df["media_name"] != "").sum()
        print(f"âœ… ì™„ë£Œ: {len(df)}ê°œ ê¸°ì‚¬ì— ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€")
        print(f"  - ê¸°ì¡´ ë””ë ‰í† ë¦¬: {len(existing_media) - len(new_domains)}ê°œ")
        if new_domains:
            print(f"  - ì‹ ê·œ ë¶„ë¥˜: {len(new_domains)}ê°œ")

        return df

    except Exception as e:
        print(f"âš ï¸  ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
        return df
