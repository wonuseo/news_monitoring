"""
classify.py - AI Classification Module
AIë¥¼ í†µí•œ ì¹´í…Œê³ ë¦¬í™” ë° ìœ„í—˜ë„ íŒë‹¨
1ë‹¨ê³„: ê°ì • ë¶„ì„ (ê¸ì •/ì¤‘ë¦½/ë¶€ì •)
2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
3ë‹¨ê³„: ë¶€ì • ê¸°ì‚¬ì— ëŒ€í•´ì„œë§Œ ìœ„í—˜ë„ í‰ê°€ (ìƒ/ì¤‘/í•˜)
"""

import json
import time
import re
import requests
from datetime import datetime
from typing import Dict, List, Tuple
import pandas as pd


OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"

# í•œêµ­ì–´ ì¹´í…Œê³ ë¦¬
CATEGORIES = [
    "ë²•ë¥ /ê·œì œ",      # ë²•ì  ë¬¸ì œ, ê·œì œ, ì†Œì†¡
    "ë³´ì•ˆ/ë°ì´í„°",    # í•´í‚¹, ë°ì´í„° ìœ ì¶œ
    "ì•ˆì „/ì‚¬ê³ ",      # í™”ì¬, ì‚¬ê³ , ì•ˆì „ ë¬¸ì œ
    "ì¬ë¬´/ì‹¤ì ",      # ì‹¤ì , ì£¼ê°€, íˆ¬ì
    "ì œí’ˆ/ì„œë¹„ìŠ¤",    # ì‹ ê·œ ì„œë¹„ìŠ¤, ë¦¬ë‰´ì–¼
    "í‰íŒ/SNS",       # ì—¬ë¡ , SNS ì´ìŠˆ
    "ìš´ì˜/ê¸°íƒ€",      # ì¼ë°˜ ìš´ì˜, ì¸ì‚¬
]


def call_openai_batch(articles: List[Dict], task_type: str, openai_key: str, 
                      retry: bool = True) -> Dict[int, Dict]:
    """
    OpenAI API ë°°ì¹˜ í˜¸ì¶œ
    
    Args:
        articles: ê¸°ì‚¬ ëª©ë¡ [{"title": ..., "description": ...}, ...]
        task_type: "sentiment" / "categorize" / "risk_assess"
        openai_key: OpenAI API í‚¤
        retry: ì¬ì‹œë„ ì—¬ë¶€
    
    Returns:
        {idx: {"sentiment": "ê¸ì •", ...}} í˜•íƒœì˜ ê²°ê³¼
    """
    if task_type == "sentiment":
        # 1ë‹¨ê³„: ê°ì • ë¶„ì„
        articles_text = ""
        for idx, article in enumerate(articles):
            articles_text += f"\n[{idx}]\nì œëª©: {article['title']}\nì„¤ëª…: {article['description'][:150]}\n"
        
        prompt = f"""ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê° ê¸°ì‚¬ë¥¼ ê¸ì •/ì¤‘ë¦½/ë¶€ì •ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

ê¸°ì‚¬ ëª©ë¡:{articles_text}

JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”:
[
  {{"id": 0, "sentiment": "ê¸ì •"}},
  {{"id": 1, "sentiment": "ë¶€ì •"}},
  ...
]

ê°ì • ë¶„ë¥˜ ê¸°ì¤€:
- ê¸ì •: ì¢‹ì€ ì†Œì‹, ì„±ê³¼, ìˆ˜ìƒ, ì„±ì¥ ë“±
- ì¤‘ë¦½: ì¼ë°˜ ì†Œì‹, ì‚¬ì‹¤ ì „ë‹¬
- ë¶€ì •: ì‚¬ê³ , ë…¼ë€, ë¹„íŒ, ì†ì‹¤ ë“±

JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
        
        max_tokens = len(articles) * 20
    
    elif task_type == "categorize":
        # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        articles_text = ""
        for idx, article in enumerate(articles):
            articles_text += f"\n[{idx}] {article['sentiment']}\nì œëª©: {article['title']}\n"
        
        prompt = f"""ë‹¹ì‹ ì€ í˜¸í…” ì—…ê³„ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê° ê¸°ì‚¬ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

ê¸°ì‚¬ ëª©ë¡:{articles_text}

JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”:
[
  {{"id": 0, "category": "ì œí’ˆ/ì„œë¹„ìŠ¤"}},
  {{"id": 1, "category": "ì•ˆì „/ì‚¬ê³ "}},
  ...
]

ì¹´í…Œê³ ë¦¬ (í•˜ë‚˜ë§Œ ì„ íƒ):
- ë²•ë¥ /ê·œì œ: ë²•ì  ë¬¸ì œ, ê·œì œ, ì†Œì†¡, ì¡°ì‚¬
- ë³´ì•ˆ/ë°ì´í„°: í•´í‚¹, ì •ë³´ ìœ ì¶œ, ê°œì¸ì •ë³´ ì¹¨í•´
- ì•ˆì „/ì‚¬ê³ : í™”ì¬, ì‚¬ë§, ë¶€ìƒ, ì•ˆì „ ë¬¸ì œ
- ì¬ë¬´/ì‹¤ì : ì‹¤ì  ë°œí‘œ, ì£¼ê°€, íˆ¬ì, ì¬ë¬´ ì„±ê³¼
- ì œí’ˆ/ì„œë¹„ìŠ¤: ì‹ ê·œ ì˜¤í”ˆ, ë¦¬ë‰´ì–¼, ì œíœ´, í”„ë¡œëª¨ì…˜
- í‰íŒ/SNS: ì—¬ë¡ , SNS ì´ìŠˆ, ë¶ˆë§¤ìš´ë™, ê³ ê° ë¶ˆë§Œ
- ìš´ì˜/ê¸°íƒ€: ì¼ë°˜ ìš´ì˜, ì¸ì‚¬, ê¸°íƒ€

JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
        
        max_tokens = len(articles) * 25
    
    else:  # risk_assess
        # 3ë‹¨ê³„: ìœ„í—˜ë„ í‰ê°€ (ë¶€ì • ê¸°ì‚¬ë§Œ)
        articles_text = ""
        for idx, article in enumerate(articles):
            articles_text += f"\n[{idx}] {article['category']}\nì œëª©: {article['title']}\n"
        
        prompt = f"""ë‹¹ì‹ ì€ í˜¸í…” ì—…ê³„ ë¦¬ìŠ¤í¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê° ë¶€ì • ê¸°ì‚¬ì˜ ìœ„í—˜ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”.

ë¶€ì • ê¸°ì‚¬ ëª©ë¡:{articles_text}

JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”:
[
  {{"id": 0, "risk_level": "ìƒ", "reason": "í™”ì¬ ì‚¬ê³ "}},
  {{"id": 1, "risk_level": "ì¤‘", "reason": "ê³ ê° ë¶ˆë§Œ"}},
  ...
]

ìœ„í—˜ë„ ê¸°ì¤€:
- ìƒ: ì¦‰ê° ëŒ€ì‘ í•„ìš”. ì‚¬ë§/í™”ì¬/ëŒ€ê·œëª¨ ìœ ì¶œ/ì˜ì—…ì •ì§€/ì§‘ë‹¨ì†Œì†¡ ë“±
- ì¤‘: ëª¨ë‹ˆí„°ë§ í•„ìš”. ê³ ê° ë¶ˆë§Œ í™•ì‚°/ê·œì œ ì¡°ì‚¬/í‰íŒ ì†ìƒ ë“±
- í•˜: ê²½ë¯¸í•œ ì˜í–¥. ì†Œê·œëª¨ ë¶ˆë§Œ/ì¼ë°˜ ë…¼ë€ ë“±

ì´ìœ (reason)ëŠ” 3-5ë‹¨ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
        
        max_tokens = len(articles) * 35
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {openai_key}"
    }
    
    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì •í™•í•œ JSON ì‘ë‹µë§Œ ì œê³µí•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2,
        "max_tokens": max_tokens
    }
    
    try:
        response = requests.post(OPENAI_API_URL, headers=headers, json=payload, timeout=60)
        
        if response.status_code == 401:
            raise RuntimeError("OpenAI API ì¸ì¦ ì‹¤íŒ¨ (401). API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        elif response.status_code == 429:
            print("âš ï¸  OpenAI ìš”ì²­ í•œë„ ì´ˆê³¼ (429). 5ì´ˆ ëŒ€ê¸° ì¤‘...")
            time.sleep(5)
            if retry:
                return call_openai_batch(articles, task_type, openai_key, retry=False)
            else:
                raise RuntimeError("OpenAI ìš”ì²­ í•œë„ ì´ˆê³¼ (ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨)")
        elif response.status_code >= 500:
            raise RuntimeError(f"OpenAI ì„œë²„ ì˜¤ë¥˜ ({response.status_code})")
        
        response.raise_for_status()
        data = response.json()
        
        content = data["choices"][0]["message"]["content"].strip()
        
        # Markdown ì½”ë“œ ë¸”ë¡ ì œê±°
        if content.startswith("```"):
            content = re.sub(r'^```json?\s*', '', content)
            content = re.sub(r'\s*```$', '', content)
        
        results = json.loads(content)
        
        # ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ {id: result}
        result_dict = {}
        for item in results:
            idx = item.get("id")
            if idx is not None:
                result_dict[idx] = item
        
        return result_dict
    
    except (json.JSONDecodeError, KeyError, requests.exceptions.RequestException) as e:
        print(f"âš ï¸  ë°°ì¹˜ {task_type} ì˜¤ë¥˜: {e}")
        if retry:
            print("ì¬ì‹œë„ ì¤‘...")
            time.sleep(2)
            return call_openai_batch(articles, task_type, openai_key, retry=False)
        else:
            return {}


def should_classify(row: Dict, max_competitor_classify: int, 
                   competitor_count: Dict[str, int]) -> bool:
    """ë¶„ë¥˜ ëŒ€ìƒ ì—¬ë¶€ íŒë‹¨"""
    # ìš°ë¦¬ ë¸Œëœë“œëŠ” ì „ë¶€ ë¶„ë¥˜
    if row.get("group") == "OUR":
        return True
    
    # ê²½ìŸì‚¬ëŠ” ê° ë¸Œëœë“œë‹¹ ìµœì‹  Nê°œë§Œ ë¶„ë¥˜
    if row.get("group") == "COMPETITOR":
        query = row.get("query", "")
        count = competitor_count.get(query, 0)
        if count < max_competitor_classify:
            competitor_count[query] = count + 1
            return True
    
    return False


def classify_all(df: pd.DataFrame, openai_key: str, 
                max_competitor_classify: int, chunk_size: int, 
                dry_run: bool) -> pd.DataFrame:
    """
    3ë‹¨ê³„ ë¶„ë¥˜ í”„ë¡œì„¸ìŠ¤
    1. ê°ì • ë¶„ì„ (ì „ì²´)
    2. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì „ì²´)
    3. ìœ„í—˜ë„ í‰ê°€ (ë¶€ì • ê¸°ì‚¬ë§Œ)
    """
    df = df.copy()
    
    # ì»¬ëŸ¼ ì´ˆê¸°í™”
    df["sentiment"] = ""
    df["category"] = ""
    df["risk_level"] = ""
    df["reason"] = ""
    df["classified_at"] = ""
    
    if dry_run:
        print("ğŸ”¬ DRY RUN ëª¨ë“œ: AI ë¶„ë¥˜ ìƒëµ")
        return df
    
    # ë¶„ë¥˜ ëŒ€ìƒ ìˆ˜ì§‘
    competitor_count = {}
    articles_to_classify = []
    indices_to_classify = []
    
    for idx, row in df.iterrows():
        if should_classify(row.to_dict(), max_competitor_classify, competitor_count):
            articles_to_classify.append({
                'title': row['title'],
                'description': row['description']
            })
            indices_to_classify.append(idx)
    
    if len(articles_to_classify) == 0:
        print("âš ï¸  ë¶„ë¥˜í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
        return df
    
    total = len(articles_to_classify)
    print(f"\nğŸ¤– AI ë¶„ë¥˜ ì‹œì‘: {total}ê°œ ê¸°ì‚¬ (ì²­í¬ í¬ê¸°: {chunk_size})")
    
    timestamp = datetime.now().isoformat()
    
    # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for chunk_start in range(0, total, chunk_size):
        chunk_end = min(chunk_start + chunk_size, total)
        chunk_articles = articles_to_classify[chunk_start:chunk_end]
        chunk_indices = indices_to_classify[chunk_start:chunk_end]
        chunk_num = (chunk_start // chunk_size) + 1
        total_chunks = (total + chunk_size - 1) // chunk_size
        
        print(f"\n--- ì²­í¬ {chunk_num}/{total_chunks} ({len(chunk_articles)}ê°œ ê¸°ì‚¬) ---")
        
        # Step 1: ê°ì • ë¶„ì„
        print("  [1/3] ê°ì • ë¶„ì„ ì¤‘...")
        sentiment_results = call_openai_batch(chunk_articles, "sentiment", openai_key)
        
        for i, idx in enumerate(chunk_indices):
            if i in sentiment_results:
                sentiment = sentiment_results[i].get("sentiment", "ì¤‘ë¦½")
                df.at[idx, "sentiment"] = sentiment
                chunk_articles[i]["sentiment"] = sentiment
            else:
                df.at[idx, "sentiment"] = "ì¤‘ë¦½"
                chunk_articles[i]["sentiment"] = "ì¤‘ë¦½"
        
        time.sleep(1)
        
        # Step 2: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        print("  [2/3] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...")
        category_results = call_openai_batch(chunk_articles, "categorize", openai_key)
        
        for i, idx in enumerate(chunk_indices):
            if i in category_results:
                category = category_results[i].get("category", "ìš´ì˜/ê¸°íƒ€")
                if category not in CATEGORIES:
                    category = "ìš´ì˜/ê¸°íƒ€"
                df.at[idx, "category"] = category
                chunk_articles[i]["category"] = category
            else:
                df.at[idx, "category"] = "ìš´ì˜/ê¸°íƒ€"
                chunk_articles[i]["category"] = "ìš´ì˜/ê¸°íƒ€"
        
        time.sleep(1)
        
        # Step 3: ìœ„í—˜ë„ í‰ê°€ (ë¶€ì • ê¸°ì‚¬ë§Œ)
        negative_articles = [art for art in chunk_articles if art.get("sentiment") == "ë¶€ì •"]
        negative_indices_map = {
            i: chunk_indices[i] 
            for i, art in enumerate(chunk_articles) 
            if art.get("sentiment") == "ë¶€ì •"
        }
        
        if len(negative_articles) > 0:
            print(f"  [3/3] ìœ„í—˜ë„ í‰ê°€ ì¤‘ (ë¶€ì • ê¸°ì‚¬ {len(negative_articles)}ê°œ)...")
            risk_results = call_openai_batch(negative_articles, "risk_assess", openai_key)
            
            for i, idx in negative_indices_map.items():
                # negative_articlesì˜ ì¸ë±ìŠ¤ëŠ” 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ ë§¤í•‘ í•„ìš”
                neg_idx = list(negative_indices_map.keys()).index(i)
                if neg_idx in risk_results:
                    risk_level = risk_results[neg_idx].get("risk_level", "í•˜")
                    reason = risk_results[neg_idx].get("reason", "í‰ê°€ ì‹¤íŒ¨")
                    df.at[idx, "risk_level"] = risk_level
                    df.at[idx, "reason"] = reason
                else:
                    df.at[idx, "risk_level"] = "í•˜"
                    df.at[idx, "reason"] = "í‰ê°€ ì‹¤íŒ¨"
        else:
            print("  [3/3] ë¶€ì • ê¸°ì‚¬ ì—†ìŒ, ìœ„í—˜ë„ í‰ê°€ ìƒëµ")
        
        # ê¸ì •/ì¤‘ë¦½ ê¸°ì‚¬ëŠ” ìœ„í—˜ë„ ì—†ìŒ
        for i, idx in enumerate(chunk_indices):
            if df.at[idx, "sentiment"] != "ë¶€ì •":
                df.at[idx, "risk_level"] = "-"
                df.at[idx, "reason"] = "-"
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        for idx in chunk_indices:
            df.at[idx, "classified_at"] = timestamp
        
        print(f"  âœ… ì²­í¬ {chunk_num}/{total_chunks} ì™„ë£Œ")
        time.sleep(1)
    
    print(f"\nâœ… AI ë¶„ë¥˜ ì™„ë£Œ: {total}ê°œ ê¸°ì‚¬ ì²˜ë¦¬")
    return df
