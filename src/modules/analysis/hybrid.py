"""
hybrid.py - Hybrid Analysis Orchestrator
Rule-Based + LLM í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œìŠ¤í…œ
"""

import time
import json
from datetime import datetime
from typing import Dict, List, Optional
import pandas as pd

from .rule_engine import load_rules, analyze_batch_rb
from .llm_engine import load_prompts, analyze_article_llm


def classify_hybrid(
    df: pd.DataFrame,
    openai_key: str,
    chunk_size: int = 50,
    dry_run: bool = False,
    max_competitor_classify: int = 50
) -> pd.DataFrame:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜

    3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤:
    1. Rule-Based ë¶„ì„ (ì „ì²´ ê¸°ì‚¬)
    2. LLM ë¶„ì„ (ì¡°ê±´ë¶€: ìš°ë¦¬ ë¸Œëœë“œ ì „ì²´ + ê²½ìŸì‚¬ ìƒìœ„ Nê°œ)
    3. ê²°ê³¼ ë³‘í•© ë° DataFrame ë°˜í™˜

    Args:
        df: ì…ë ¥ DataFrame (title, description í•„ìˆ˜)
        openai_key: OpenAI API í‚¤
        chunk_size: LLM ë°°ì¹˜ í¬ê¸°
        dry_run: Trueë©´ LLM í˜¸ì¶œ ìƒëµ (Rule-Basedë§Œ)
        max_competitor_classify: ê²½ìŸì‚¬ë³„ ìµœëŒ€ ë¶„ë¥˜ ê°œìˆ˜

    Returns:
        ë¶„ì„ ê²°ê³¼ê°€ ì¶”ê°€ëœ DataFrame
    """
    df = df.copy()

    # ì´ˆê¸°í™”: ëª¨ë“  ê²°ê³¼ ì»¬ëŸ¼
    rb_columns = [
        "brand_mentions",
        "brand_scope_rb",
        "sentiment_rb",
        "danger_rb",
        "risk_score_rb",
        "issue_category_rb",
        "coverage_themes_rb",
        "reason_codes_rb",
        "matched_rules_rb",
        "score_breakdown_rb"
    ]

    llm_columns = [
        "sentiment_llm",
        "sentiment_llm_confidence",
        "sentiment_llm_evidence",
        "sentiment_llm_rationale",
        "sentiment_final",
        "sentiment_final_confidence",
        "sentiment_final_decision_rule",
        "sentiment_final_evidence",
        "sentiment_final_rationale",
        "danger_llm",
        "danger_llm_confidence",
        "danger_llm_evidence",
        "danger_llm_rationale",
        "danger_final",
        "danger_final_confidence",
        "danger_final_decision_rule",
        "danger_final_evidence",
        "danger_final_rationale",
        "issue_category_llm",
        "coverage_themes_llm",
        "category_llm_confidence",
        "category_llm_evidence",
        "category_llm_rationale",
        "issue_category_final",
        "coverage_themes_final",
        "category_final_confidence",
        "category_final_decision_rule",
        "category_final_evidence",
        "category_final_rationale"
    ]

    # ì»¬ëŸ¼ ì´ˆê¸°í™”
    for col in rb_columns + llm_columns:
        df[col] = None

    df["classified_at"] = ""

    # Load configs
    print("\nğŸ”§ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘...")
    rules = load_rules()
    prompts_config = load_prompts()

    # ========================================
    # STEP 1: Rule-Based ë¶„ì„ (ì „ì²´ ê¸°ì‚¬)
    # ========================================
    print("\n[1/3] Rule-Based ë¶„ì„ ì¤‘...")
    articles = df[["title", "description"]].fillna("").to_dict("records")
    rb_results = analyze_batch_rb(articles, rules)

    # RB ê²°ê³¼ë¥¼ DataFrameì— ë³‘í•©
    for idx, rb_result in enumerate(rb_results):
        for col in rb_columns:
            if col in rb_result:
                # JSON serializable íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                value = rb_result[col]
                if isinstance(value, (dict, list)):
                    value = json.dumps(value, ensure_ascii=False)
                df.at[idx, col] = value

    print(f"âœ… Rule-Based ë¶„ì„ ì™„ë£Œ: {len(df)}ê°œ ê¸°ì‚¬")

    if dry_run:
        print("ğŸ”¬ DRY RUN ëª¨ë“œ: LLM ë¶„ì„ ìƒëµ")
        return df

    # ========================================
    # STEP 2: LLM ë¶„ì„ ëŒ€ìƒ ì„ íƒ
    # ========================================
    print("\n[2/3] LLM ë¶„ì„ ëŒ€ìƒ ì„ íƒ ì¤‘...")

    # ë¶„ë¥˜ ëŒ€ìƒ í•„í„°ë§ (ìš°ë¦¬ ë¸Œëœë“œ ì „ì²´ + ê²½ìŸì‚¬ ìƒìœ„ Nê°œ)
    indices_to_classify = []
    competitor_count = {}

    for idx, row in df.iterrows():
        group = row.get("group", "")

        # ìš°ë¦¬ ë¸Œëœë“œëŠ” ì „ë¶€
        if group == "OUR":
            indices_to_classify.append(idx)
        # ê²½ìŸì‚¬ëŠ” ê° ë¸Œëœë“œë‹¹ ìµœì‹  Nê°œ
        elif group == "COMPETITOR":
            query = row.get("query", "")
            count = competitor_count.get(query, 0)
            if count < max_competitor_classify:
                competitor_count[query] = count + 1
                indices_to_classify.append(idx)

    if len(indices_to_classify) == 0:
        print("âš ï¸  LLM ë¶„ì„ ëŒ€ìƒ ì—†ìŒ")
        return df

    print(f"  ì„ íƒëœ ê¸°ì‚¬: {len(indices_to_classify)}ê°œ")
    print(f"  - ìš°ë¦¬ ë¸Œëœë“œ: {sum(1 for idx in indices_to_classify if df.at[idx, 'group'] == 'OUR')}ê°œ")
    print(f"  - ê²½ìŸì‚¬: {sum(1 for idx in indices_to_classify if df.at[idx, 'group'] == 'COMPETITOR')}ê°œ")

    # ========================================
    # STEP 3: LLM ë¶„ì„ (ì²­í¬ ë‹¨ìœ„)
    # ========================================
    print(f"\n[3/3] LLM ë¶„ì„ ì¤‘ (ì²­í¬ í¬ê¸°: {chunk_size})...")

    timestamp = datetime.now().isoformat()
    total = len(indices_to_classify)
    total_chunks = (total + chunk_size - 1) // chunk_size

    for chunk_start in range(0, total, chunk_size):
        chunk_end = min(chunk_start + chunk_size, total)
        chunk_indices = indices_to_classify[chunk_start:chunk_end]
        chunk_num = (chunk_start // chunk_size) + 1

        print(f"\n--- ì²­í¬ {chunk_num}/{total_chunks} ({len(chunk_indices)}ê°œ ê¸°ì‚¬) ---")

        for i, idx in enumerate(chunk_indices):
            article = {
                "title": df.at[idx, "title"],
                "description": df.at[idx, "description"]
            }

            # RB ê²°ê³¼ íŒŒì‹± (JSON string â†’ dict/list)
            rb_result = {}
            for col in rb_columns:
                value = df.at[idx, col]
                if pd.isna(value):
                    continue
                # JSON stringì´ë©´ íŒŒì‹±
                if isinstance(value, str) and (value.startswith("{") or value.startswith("[")):
                    try:
                        rb_result[col] = json.loads(value)
                    except:
                        rb_result[col] = value
                else:
                    rb_result[col] = value

            # LLM ë¶„ì„ ìˆ˜í–‰
            try:
                llm_result = analyze_article_llm(article, rb_result, prompts_config, openai_key)

                # LLM ê²°ê³¼ë¥¼ DataFrameì— ë³‘í•©
                for col in llm_columns:
                    if col in llm_result:
                        value = llm_result[col]
                        # JSON serializable íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                        if isinstance(value, (dict, list)):
                            value = json.dumps(value, ensure_ascii=False)
                        df.at[idx, col] = value

                df.at[idx, "classified_at"] = timestamp

                # Progress indicator
                if (i + 1) % 10 == 0:
                    print(f"  ì§„í–‰: {i + 1}/{len(chunk_indices)}ê°œ ì™„ë£Œ")

                # Rate limiting
                time.sleep(0.5)

            except Exception as e:
                print(f"  âš ï¸  ê¸°ì‚¬ {idx} LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
                # Fallback: RB ê²°ê³¼ ì‚¬ìš©
                df.at[idx, "sentiment_final"] = df.at[idx, "sentiment_rb"]
                df.at[idx, "sentiment_final_decision_rule"] = f"LLM failed: {str(e)}"
                df.at[idx, "danger_final"] = df.at[idx, "danger_rb"]
                df.at[idx, "danger_final_decision_rule"] = f"LLM failed: {str(e)}"
                df.at[idx, "classified_at"] = timestamp

        print(f"  âœ… ì²­í¬ {chunk_num}/{total_chunks} ì™„ë£Œ")
        time.sleep(1)

    print(f"\nâœ… í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì™„ë£Œ: {total}ê°œ ê¸°ì‚¬ ì²˜ë¦¬")

    return df


def get_classification_stats(df: pd.DataFrame) -> Dict:
    """
    ë¶„ë¥˜ í†µê³„ ìƒì„±

    Args:
        df: ë¶„ì„ ê²°ê³¼ DataFrame

    Returns:
        í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    stats = {}

    # Sentiment distribution (Final)
    if "sentiment_final" in df.columns:
        sentiment_counts = df["sentiment_final"].value_counts().to_dict()
        stats["sentiment_final"] = sentiment_counts

    # Danger distribution (Final)
    if "danger_final" in df.columns:
        danger_counts = df["danger_final"].value_counts().to_dict()
        stats["danger_final"] = danger_counts

    # Brand scope distribution
    if "brand_scope_rb" in df.columns:
        scope_counts = df["brand_scope_rb"].value_counts().to_dict()
        stats["brand_scope_rb"] = scope_counts

    # Issue category distribution
    if "issue_category_rb" in df.columns:
        category_counts = df["issue_category_rb"].value_counts().to_dict()
        stats["issue_category_rb"] = category_counts

    # Average confidence scores
    if "sentiment_final_confidence" in df.columns:
        avg_sentiment_conf = df["sentiment_final_confidence"].apply(
            lambda x: float(x) if pd.notna(x) and x != "" else 0
        ).mean()
        stats["avg_sentiment_confidence"] = round(avg_sentiment_conf, 3)

    if "danger_final_confidence" in df.columns:
        avg_danger_conf = df["danger_final_confidence"].apply(
            lambda x: float(x) if pd.notna(x) and x != "" else 0
        ).mean()
        stats["avg_danger_confidence"] = round(avg_danger_conf, 3)

    return stats


def print_classification_stats(stats: Dict):
    """
    ë¶„ë¥˜ í†µê³„ ì¶œë ¥

    Args:
        stats: get_classification_stats() ê²°ê³¼
    """
    print("\nğŸ“Š ë¶„ë¥˜ í†µê³„:")

    if "sentiment_final" in stats:
        print("\n  Sentiment (Final):")
        for sentiment, count in stats["sentiment_final"].items():
            print(f"    - {sentiment}: {count}ê°œ")

    if "danger_final" in stats:
        print("\n  Danger (Final):")
        for danger, count in stats["danger_final"].items():
            print(f"    - {danger}: {count}ê°œ")

    if "brand_scope_rb" in stats:
        print("\n  Brand Scope:")
        for scope, count in stats["brand_scope_rb"].items():
            print(f"    - {scope}: {count}ê°œ")

    if "issue_category_rb" in stats:
        print("\n  Issue Category:")
        for category, count in sorted(stats["issue_category_rb"].items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"    - {category}: {count}ê°œ")

    if "avg_sentiment_confidence" in stats:
        print(f"\n  í‰ê·  Sentiment ì‹ ë¢°ë„: {stats['avg_sentiment_confidence']:.2%}")

    if "avg_danger_confidence" in stats:
        print(f"  í‰ê·  Danger ì‹ ë¢°ë„: {stats['avg_danger_confidence']:.2%}")
