"""
threshold_tuner.py - Cross-query ì„ê³„ê°’ íŠœë‹ ë„êµ¬

2ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°:
  Step 1 (ëŠë¦¼, 1íšŒ): Sheets ë¡œë“œ + TF-IDF ë²¡í„°í™” â†’ í˜ì–´ ì ìˆ˜ ìºì‹œ
  Step 2 (ë¹ ë¦„, ë°˜ë³µ): ìºì‹œ ë¡œë“œ â†’ ì„ê³„ê°’ ì ìš© â†’ í†µê³„/ìƒ˜í”Œ ì¶œë ¥

ì‚¬ìš©ë²•:
  # Step 1: í˜ì–´ ì ìˆ˜ ì‚¬ì „ ê³„ì‚° (Sheets ì—°ê²° í•„ìš”, ~1-2ë¶„)
  python scripts/threshold_tuner.py precompute

  # Step 2: í˜„ì¬ ì„ê³„ê°’ ê¸°ì¤€ í†µê³„ + ìƒ˜í”Œ
  python scripts/threshold_tuner.py test

  # Step 2: íŠ¹ì • ì„ê³„ê°’ í…ŒìŠ¤íŠ¸
  python scripts/threshold_tuner.py test --t_cos 0.60 --t_jac 0.10

  # Step 2: ì—¬ëŸ¬ ì„ê³„ê°’ ì¡°í•© ìŠ¤ìœ• (summary í…Œì´ë¸”)
  python scripts/threshold_tuner.py sweep

  # Step 2: ìŠ¤ìœ• ë²”ìœ„ ì»¤ìŠ¤í…€
  python scripts/threshold_tuner.py sweep --t_cos_range 0.55,0.60,0.65,0.70 --t_jac_range 0.10,0.15,0.20
"""

import os
import re
import sys
import argparse
import random
from pathlib import Path
from typing import List, Dict, Tuple
from itertools import product

import numpy as np
import pandas as pd
from dotenv import load_dotenv

sys.path.insert(0, str(Path(__file__).parent.parent))

load_dotenv()

# â”€â”€â”€ ê¸°ë³¸ê°’ (source_verifier.py ì™€ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT = {
    "t_cos": 0.65,
    "t_jac": 0.15,
    "d_cos": 0.55,
    "d_jac": 0.08,
    "border_t_cos_lo": 0.58,
    "border_t_cos_hi": 0.65,
    "border_t_jac_min": 0.20,
    "border_d_cos_lo": 0.48,
    "border_d_cos_hi": 0.55,
    "border_d_jac_min": 0.12,
}

CACHE_PATH = Path("scripts/.pair_cache.csv")
SAMPLE_N = 5


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _clean_html(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s = re.sub(r"<[^>]+>", " ", s)
    s = s.replace("&quot;", " ").replace("&amp;", "&")
    s = re.sub(r"\s+", " ", s).strip()
    return s


def _tokenize(s: str, min_len: int = 2) -> set:
    if not isinstance(s, str) or not s.strip():
        return set()
    toks = re.findall(r"[ê°€-í£a-z0-9]+", s.lower())
    return {t for t in toks if len(t) >= min_len}


def _jaccard(a: set, b: set) -> float:
    if not a or not b:
        return 0.0
    inter = len(a & b)
    union = len(a | b)
    return inter / union if union > 0 else 0.0


def classify(row, cfg: dict) -> str:
    t_cos, t_jac = row["t_cos"], row["t_jac"]
    d_cos, d_jac = row["d_cos"], row["d_jac"]

    if t_cos >= cfg["t_cos"] and t_jac >= cfg["t_jac"]:
        return "auto_title"
    if d_cos >= cfg["d_cos"] and d_jac >= cfg["d_jac"]:
        return "auto_desc"

    t_border = cfg["border_t_cos_lo"] <= t_cos < cfg["border_t_cos_hi"] and t_jac >= cfg["border_t_jac_min"]
    d_border = cfg["border_d_cos_lo"] <= d_cos < cfg["border_d_cos_hi"] and d_jac >= cfg["border_d_jac_min"]
    if t_border:
        return "border_title"
    if d_border:
        return "border_desc"
    return "no_merge"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Step 1: precompute
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_precompute(args):
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    from src.modules.export.sheets import connect_sheets

    creds_path = os.getenv("GOOGLE_SHEETS_CREDENTIALS_PATH", "service-account.json")
    sheet_id = os.getenv("GOOGLE_SHEET_ID")
    if not os.path.exists(creds_path) or not sheet_id:
        print("âŒ GOOGLE_SHEETS_CREDENTIALS_PATH ë˜ëŠ” GOOGLE_SHEET_ID ë¯¸ì„¤ì •")
        return

    print(f"ğŸ“Š Google Sheets ì—°ê²° ì¤‘...")
    sp = connect_sheets(creds_path, sheet_id)
    ws = sp.worksheet(args.sheet)
    rows = ws.get_all_values()
    if not rows:
        print("âŒ ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŒ")
        return
    headers = rows[0]
    data = rows[1:args.max_rows + 1] if args.max_rows else rows[1:]
    df = pd.DataFrame(data, columns=headers)
    print(f"  âœ… {len(df)}í–‰ ë¡œë“œ ì™„ë£Œ")

    # í›„ë³´ ìˆ˜ì§‘
    candidates: List[Dict] = []
    clustered_mask = df["cluster_id"].astype(str).str.strip() != ""

    for cid, cgroup in df[clustered_mask].groupby("cluster_id"):
        repr_idx = cgroup["pub_datetime"].astype(str).idxmin() if "pub_datetime" in df.columns else cgroup.index[0]
        candidates.append({
            "repr_idx": repr_idx,
            "cluster_id": str(cid),
            "query": str(cgroup["query"].iloc[0]) if "query" in cgroup.columns else "",
            "source": str(cgroup["source"].iloc[0]) if "source" in cgroup.columns else "",
        })

    unclustered_mask = ~clustered_mask
    if "source" in df.columns:
        unclustered_mask &= df["source"] == "ì¼ë°˜ê¸°ì‚¬"
    if "news_category" in df.columns:
        unclustered_mask &= df["news_category"] != "ë¹„ê´€ë ¨"
    for idx in df[unclustered_mask].index:
        candidates.append({
            "repr_idx": idx,
            "cluster_id": "",
            "query": str(df.at[idx, "query"]) if "query" in df.columns else "",
            "source": "ì¼ë°˜ê¸°ì‚¬",
        })

    n = len(candidates)
    print(f"  í›„ë³´ {n}ê°œ â†’ {n*(n-1)//2}ìŒ ê³„ì‚° ì¤‘...")

    repr_indices = [c["repr_idx"] for c in candidates]
    title_texts = [_clean_html(str(df.at[idx, "title"])) for idx in repr_indices]
    desc_texts = [_clean_html(str(df.at[idx, "description"])) for idx in repr_indices]
    title_tok = [_tokenize(t) for t in title_texts]
    desc_tok = [_tokenize(d) for d in desc_texts]

    title_corpus = [t if t.strip() else " " for t in title_texts]
    desc_corpus = [d if d.strip() else " " for d in desc_texts]

    print("  TF-IDF ë²¡í„°í™” ì¤‘...")
    vec_t = TfidfVectorizer(analyzer="char", ngram_range=(3, 5), min_df=1)
    vec_d = TfidfVectorizer(analyzer="char", ngram_range=(3, 5), min_df=1)
    X_t = vec_t.fit_transform(title_corpus)
    X_d = vec_d.fit_transform(desc_corpus)
    sim_t = cosine_similarity(X_t)
    sim_d = cosine_similarity(X_d)
    print("  âœ… ë²¡í„°í™” ì™„ë£Œ")

    print("  í˜ì–´ ë ˆì½”ë“œ ìƒì„± ì¤‘...")
    records = []
    for i in range(n):
        for j in range(i + 1, n):
            ci, cj = candidates[i], candidates[j]
            if ci["cluster_id"] and ci["cluster_id"] == cj["cluster_id"]:
                continue
            if ci["query"] == cj["query"] and not ci["cluster_id"] and not cj["cluster_id"]:
                continue
            records.append({
                "i": i, "j": j,
                "title_a": str(df.at[ci["repr_idx"], "title"])[:80],
                "title_b": str(df.at[cj["repr_idx"], "title"])[:80],
                "query_a": ci["query"], "query_b": cj["query"],
                "cluster_id_a": ci["cluster_id"] or "(ë¯¸í´ëŸ¬ìŠ¤í„°)",
                "cluster_id_b": cj["cluster_id"] or "(ë¯¸í´ëŸ¬ìŠ¤í„°)",
                "source_a": ci["source"], "source_b": cj["source"],
                "t_cos": round(float(sim_t[i, j]), 4),
                "t_jac": round(_jaccard(title_tok[i], title_tok[j]), 4),
                "d_cos": round(float(sim_d[i, j]), 4),
                "d_jac": round(_jaccard(desc_tok[i], desc_tok[j]), 4),
            })

    df_pairs = pd.DataFrame(records)
    CACHE_PATH.parent.mkdir(exist_ok=True)
    df_pairs.to_csv(CACHE_PATH, index=False, encoding="utf-8-sig")
    print(f"  âœ… {len(df_pairs)}ìŒ ìºì‹œ ì €ì¥: {CACHE_PATH}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Step 2: test
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _print_bucket(name: str, label: str, rows: pd.DataFrame, n: int = SAMPLE_N):
    print(f"\n{'â”€'*100}")
    print(f"  {label}")
    print(f"  ì´ {len(rows)}ìŒ")
    print(f"{'â”€'*100}")
    if rows.empty:
        print("  (ì—†ìŒ)")
        return
    sample = rows.sample(min(n, len(rows)), random_state=42)
    for k, (_, r) in enumerate(sample.iterrows(), 1):
        print(f"  [{k}] t_cos={r.t_cos:.4f}  t_jac={r.t_jac:.4f}  d_cos={r.d_cos:.4f}  d_jac={r.d_jac:.4f}")
        print(f"      A ({r.query_a} / {r.cluster_id_a}): {r.title_a}")
        print(f"      B ({r.query_b} / {r.cluster_id_b}): {r.title_b}")


def cmd_test(args):
    if not CACHE_PATH.exists():
        print(f"âŒ ìºì‹œ ì—†ìŒ. ë¨¼ì € ì‹¤í–‰: python scripts/threshold_tuner.py precompute")
        return

    df = pd.read_csv(CACHE_PATH, encoding="utf-8-sig")
    print(f"ìºì‹œ ë¡œë“œ: {len(df)}ìŒ\n")

    cfg = {**DEFAULT}
    if args.t_cos is not None: cfg["t_cos"] = args.t_cos
    if args.t_jac is not None: cfg["t_jac"] = args.t_jac
    if args.d_cos is not None: cfg["d_cos"] = args.d_cos
    if args.d_jac is not None: cfg["d_jac"] = args.d_jac
    if args.border_t_cos_lo is not None: cfg["border_t_cos_lo"] = args.border_t_cos_lo
    if args.border_t_cos_hi is not None: cfg["border_t_cos_hi"] = args.border_t_cos_hi
    if args.border_t_jac_min is not None: cfg["border_t_jac_min"] = args.border_t_jac_min
    if args.border_d_cos_lo is not None: cfg["border_d_cos_lo"] = args.border_d_cos_lo
    if args.border_d_cos_hi is not None: cfg["border_d_cos_hi"] = args.border_d_cos_hi
    if args.border_d_jac_min is not None: cfg["border_d_jac_min"] = args.border_d_jac_min

    # borderline ë²”ìœ„ëŠ” auto ì„ê³„ê°’ì— ì—°ë™ (ëª…ì‹œ ì•ˆ í–ˆì„ ë•Œ)
    if args.t_cos is not None and args.border_t_cos_hi is None:
        cfg["border_t_cos_hi"] = cfg["t_cos"]
    if args.d_cos is not None and args.border_d_cos_hi is None:
        cfg["border_d_cos_hi"] = cfg["d_cos"]

    print("ì ìš© ì„ê³„ê°’:")
    print(f"  auto_title  : t_cos>={cfg['t_cos']}  t_jac>={cfg['t_jac']}")
    print(f"  auto_desc   : d_cos>={cfg['d_cos']}  d_jac>={cfg['d_jac']}  (ì œëª© ë¯¸ë‹¬ ì‹œ)")
    print(f"  border_title: {cfg['border_t_cos_lo']}<=t_cos<{cfg['border_t_cos_hi']}  t_jac>={cfg['border_t_jac_min']}")
    print(f"  border_desc : {cfg['border_d_cos_lo']}<=d_cos<{cfg['border_d_cos_hi']}  d_jac>={cfg['border_d_jac_min']}")

    df["bucket"] = df.apply(lambda r: classify(r, cfg), axis=1)

    buckets_def = [
        ("auto_title",   f"[ìë™ë³‘í•©-ì œëª©]   t_cos>={cfg['t_cos']}  t_jac>={cfg['t_jac']}"),
        ("auto_desc",    f"[ìë™ë³‘í•©-ë³¸ë¬¸]   d_cos>={cfg['d_cos']}  d_jac>={cfg['d_jac']}  (ì œëª© ë¯¸ë‹¬)"),
        ("border_title", f"[ê²½ê³„ì„ -ì œëª©]     {cfg['border_t_cos_lo']}<=t_cos<{cfg['border_t_cos_hi']}  t_jac>={cfg['border_t_jac_min']}"),
        ("border_desc",  f"[ê²½ê³„ì„ -ë³¸ë¬¸]     {cfg['border_d_cos_lo']}<=d_cos<{cfg['border_d_cos_hi']}  d_jac>={cfg['border_d_jac_min']}"),
        ("no_merge",     "[ë³‘í•©ì•ˆë¨]        ìœ„ ëª¨ë‘ í•´ë‹¹ ì—†ìŒ"),
    ]
    print("\n" + "="*100)
    for bname, label in buckets_def:
        _print_bucket(bname, label, df[df["bucket"] == bname])
    print("\n" + "="*100)
    print("ì „ì²´ ìš”ì•½:")
    counts = df["bucket"].value_counts().reindex([b for b,_ in buckets_def], fill_value=0)
    for bname, label in buckets_def:
        print(f"  {bname:<14} {counts[bname]:>6}ìŒ   ({counts[bname]/len(df)*100:.1f}%)")
    print(f"  {'í•©ê³„':<14} {len(df):>6}ìŒ")

    # í˜„ì¬ ì„ê³„ê°’ê³¼ ë¹„êµ (ë³€ê²½ ì‚¬í•­ë§Œ)
    if any(v is not None for v in [args.t_cos, args.t_jac, args.d_cos, args.d_jac]):
        base_cfg = {**DEFAULT}
        df["bucket_base"] = df.apply(lambda r: classify(r, base_cfg), axis=1)
        changed = df[df["bucket"] != df["bucket_base"]]
        if not changed.empty:
            print(f"\nâ–¶ ê¸°ë³¸ê°’ ëŒ€ë¹„ ë²„í‚· ë³€ê²½: {len(changed)}ìŒ")
            for (b_from, b_to), grp in changed.groupby(["bucket_base", "bucket"]):
                print(f"  {b_from} â†’ {b_to}: {len(grp)}ìŒ")
                sample = grp.head(3)
                for _, r in sample.iterrows():
                    print(f"    t_cos={r.t_cos:.4f} t_jac={r.t_jac:.4f} d_cos={r.d_cos:.4f} d_jac={r.d_jac:.4f}")
                    print(f"    A: {r.title_a[:70]}")
                    print(f"    B: {r.title_b[:70]}")

    # CSV ì €ì¥
    out = Path("scripts/threshold_test_result.csv")
    df.to_csv(out, index=False, encoding="utf-8-sig")
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {out}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Step 2: sweep
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_sweep(args):
    if not CACHE_PATH.exists():
        print(f"âŒ ìºì‹œ ì—†ìŒ. ë¨¼ì € ì‹¤í–‰: python scripts/threshold_tuner.py precompute")
        return

    df = pd.read_csv(CACHE_PATH, encoding="utf-8-sig")
    total = len(df)
    print(f"ìºì‹œ ë¡œë“œ: {total}ìŒ\n")

    t_cos_range = [float(x) for x in args.t_cos_range.split(",")]
    t_jac_range = [float(x) for x in args.t_jac_range.split(",")]
    d_cos_range = [float(x) for x in args.d_cos_range.split(",")]
    d_jac_range = [float(x) for x in args.d_jac_range.split(",")]

    combos = list(product(t_cos_range, t_jac_range, d_cos_range, d_jac_range))
    print(f"ì´ {len(combos)}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸\n")

    header = f"{'t_cos':>6} {'t_jac':>6} {'d_cos':>6} {'d_jac':>6}  |  {'auto_t':>7} {'auto_d':>7} {'brd_t':>7} {'brd_d':>7} {'no_mrg':>8}  |  {'ë³‘í•©%':>6}"
    print(header)
    print("â”€" * len(header))

    rows_out = []
    for t_cos, t_jac, d_cos, d_jac in combos:
        cfg = {
            **DEFAULT,
            "t_cos": t_cos, "t_jac": t_jac,
            "d_cos": d_cos, "d_jac": d_jac,
            "border_t_cos_hi": t_cos,
            "border_d_cos_hi": d_cos,
        }
        buckets = df.apply(lambda r: classify(r, cfg), axis=1)
        counts = buckets.value_counts()
        auto_t = counts.get("auto_title", 0)
        auto_d = counts.get("auto_desc", 0)
        brd_t  = counts.get("border_title", 0)
        brd_d  = counts.get("border_desc", 0)
        no_m   = counts.get("no_merge", 0)
        merge_pct = (auto_t + auto_d) / total * 100

        mark = " â—€ í˜„ì¬" if (t_cos == DEFAULT["t_cos"] and t_jac == DEFAULT["t_jac"]
                              and d_cos == DEFAULT["d_cos"] and d_jac == DEFAULT["d_jac"]) else ""
        print(f"{t_cos:>6.2f} {t_jac:>6.2f} {d_cos:>6.2f} {d_jac:>6.2f}  |  "
              f"{auto_t:>7} {auto_d:>7} {brd_t:>7} {brd_d:>7} {no_m:>8}  |  {merge_pct:>5.1f}%{mark}")

        rows_out.append({
            "t_cos": t_cos, "t_jac": t_jac, "d_cos": d_cos, "d_jac": d_jac,
            "auto_title": auto_t, "auto_desc": auto_d,
            "border_title": brd_t, "border_desc": brd_d, "no_merge": no_m,
            "merge_pct": round(merge_pct, 2),
        })

    out = Path("scripts/threshold_sweep_result.csv")
    pd.DataFrame(rows_out).to_csv(out, index=False, encoding="utf-8-sig")
    print(f"\nâœ… ìŠ¤ìœ• ê²°ê³¼ ì €ì¥: {out}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description="Cross-query ì„ê³„ê°’ íŠœë‹ ë„êµ¬")
    sub = parser.add_subparsers(dest="cmd")

    # precompute
    p_pre = sub.add_parser("precompute", help="Sheets ë¡œë“œ + í˜ì–´ ì ìˆ˜ ìºì‹œ ìƒì„±")
    p_pre.add_argument("--sheet", default="total_result")
    p_pre.add_argument("--max_rows", type=int, default=3000)

    # test
    p_test = sub.add_parser("test", help="ì„ê³„ê°’ í…ŒìŠ¤íŠ¸ (ìƒ˜í”Œ + í†µê³„)")
    p_test.add_argument("--t_cos", type=float, default=None)
    p_test.add_argument("--t_jac", type=float, default=None)
    p_test.add_argument("--d_cos", type=float, default=None)
    p_test.add_argument("--d_jac", type=float, default=None)
    p_test.add_argument("--border_t_cos_lo", type=float, default=None)
    p_test.add_argument("--border_t_cos_hi", type=float, default=None)
    p_test.add_argument("--border_t_jac_min", type=float, default=None)
    p_test.add_argument("--border_d_cos_lo", type=float, default=None)
    p_test.add_argument("--border_d_cos_hi", type=float, default=None)
    p_test.add_argument("--border_d_jac_min", type=float, default=None)

    # sweep
    p_sw = sub.add_parser("sweep", help="ì—¬ëŸ¬ ì„ê³„ê°’ ì¡°í•© ìš”ì•½ í…Œì´ë¸”")
    p_sw.add_argument("--t_cos_range", default="0.55,0.60,0.65,0.70")
    p_sw.add_argument("--t_jac_range", default="0.10,0.15,0.20")
    p_sw.add_argument("--d_cos_range", default="0.50,0.55,0.60")
    p_sw.add_argument("--d_jac_range", default="0.08,0.12")

    args = parser.parse_args()

    if args.cmd == "precompute":
        cmd_precompute(args)
    elif args.cmd == "test":
        cmd_test(args)
    elif args.cmd == "sweep":
        cmd_sweep(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
