"""
Fix article_no sorting and duplicates - One-time migration script

ì „ì²´ result.csvë¥¼ pubDate ìˆœì„œë¡œ ì •ë ¬í•˜ê³  article_noë¥¼ ì¬í• ë‹¹í•©ë‹ˆë‹¤.
- ì¤‘ë³µ article_no ì œê±°
- pubDate ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (ê³¼ê±° ê¸°ì‚¬ = ë‚®ì€ ë²ˆí˜¸)
- article_noë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜ (5.0 â†’ 5)

ì‹¤í–‰: python scripts/fix_article_no_sorting.py
"""

import pandas as pd
from pathlib import Path
import csv
from datetime import datetime

def main():
    print("=" * 80)
    print("article_no ì¬ì •ë ¬ ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 80)
    print()

    # Load result.csv
    result_path = Path("data/result.csv")
    if not result_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {result_path}")
        return

    print(f"ğŸ“‚ ë¡œë”©: {result_path}")
    df = pd.read_csv(result_path, encoding='utf-8-sig')
    print(f"   ì´ {len(df)}ê°œ ê¸°ì‚¬")
    print()

    # Backup original file
    backup_path = result_path.parent / f"result_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    print(f"ğŸ’¾ ë°±ì—… ìƒì„±: {backup_path}")
    df.to_csv(backup_path, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_NONNUMERIC)
    print()

    # Check current state
    print("í˜„ì¬ ìƒíƒœ:")
    print(f"  - article_no íƒ€ì…: {df['article_no'].dtype}")
    print(f"  - article_no ë²”ìœ„: {df['article_no'].min():.0f} ~ {df['article_no'].max():.0f}")
    unique_nos = df['article_no'].nunique()
    total_nos = len(df[df['article_no'].notna()])
    duplicates = total_nos - unique_nos
    print(f"  - ê³ ìœ  article_no: {unique_nos}ê°œ")
    if duplicates > 0:
        print(f"  - ì¤‘ë³µ article_no: {duplicates}ê°œ âš ï¸")
    print()

    # Sort by pubDate
    print("ğŸ”§ pubDate ê¸°ì¤€ ì •ë ¬ ì¤‘...")
    df['_pub_dt_sort'] = pd.to_datetime(df['pub_datetime'], errors='coerce')

    # Check how many rows have valid dates
    valid_dates = df['_pub_dt_sort'].notna().sum()
    invalid_dates = len(df) - valid_dates
    print(f"   ìœ íš¨í•œ ë‚ ì§œ: {valid_dates}ê°œ")
    if invalid_dates > 0:
        print(f"   âš ï¸  ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ: {invalid_dates}ê°œ (ë§¨ ë’¤ë¡œ ë°°ì¹˜)")

    # Sort: ascending by date, NaN at last
    df = df.sort_values('_pub_dt_sort', ascending=True, na_position='last').reset_index(drop=True)
    df = df.drop(columns=['_pub_dt_sort'])
    print("   âœ… ì •ë ¬ ì™„ë£Œ (ì˜¤ë¦„ì°¨ìˆœ: ê³¼ê±° â†’ ìµœì‹ )")
    print()

    # Reassign article_no from 1
    print("ğŸ”§ article_no ì¬í• ë‹¹ ì¤‘ (1ë¶€í„° ì‹œì‘)...")
    df['article_no'] = range(1, len(df) + 1)

    # Convert to integer type
    df['article_no'] = df['article_no'].astype('Int64')
    print(f"   âœ… article_no ì¬í• ë‹¹ ì™„ë£Œ: 1 ~ {len(df)} (ì •ìˆ˜í˜•)")
    print()

    # Save
    print(f"ğŸ’¾ ì €ì¥ ì¤‘: {result_path}")
    df.to_csv(result_path, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_NONNUMERIC)
    print("   âœ… ì €ì¥ ì™„ë£Œ")
    print()

    # Verification
    print("ê²€ì¦:")
    df_check = pd.read_csv(result_path, encoding='utf-8-sig')
    df_check['pub_dt'] = pd.to_datetime(df_check['pub_datetime'], errors='coerce')

    print(f"  - ì´ ê¸°ì‚¬: {len(df_check)}ê°œ")
    print(f"  - article_no íƒ€ì…: {df_check['article_no'].dtype}")
    print(f"  - article_no ë²”ìœ„: {df_check['article_no'].min()} ~ {df_check['article_no'].max()}")
    print(f"  - ê³ ìœ  article_no: {df_check['article_no'].nunique()}ê°œ")

    # Check sorting
    is_sorted = df_check['pub_dt'].is_monotonic_increasing
    print(f"  - pubDate ì •ë ¬: {'âœ… ì˜¤ë¦„ì°¨ìˆœ' if is_sorted else 'âŒ ì •ë ¬ ì•ˆë¨'}")

    # Show sample
    print()
    print("ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
    print("-" * 80)
    print(df_check[['article_no', 'pub_datetime', 'title']].head(10).to_string(index=False))
    print()
    print("=" * 80)
    print("âœ… ì™„ë£Œ!")
    print(f"   ë°±ì—… íŒŒì¼: {backup_path}")
    print(f"   ê²°ê³¼ íŒŒì¼: {result_path}")
    print("=" * 80)

if __name__ == "__main__":
    main()
