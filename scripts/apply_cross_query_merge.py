"""
apply_cross_query_merge.py

ìƒˆ ì„ê³„ê°’ì´ ë°˜ì˜ëœ merge_cross_query_clustersë¥¼ í˜„ì¬ total_resultì— ì ìš©.

ë³€ê²½ë˜ëŠ” ì»¬ëŸ¼: cluster_id, source, cluster_summary
ë³€ê²½ëœ í–‰ë§Œ Sheetsì— batch ì—…ë°ì´íŠ¸ (ì „ì²´ ì¬ì—…ë¡œë“œ ì—†ìŒ).

Usage:
    # ë³€ê²½ì‚¬í•­ ë¯¸ë¦¬ë³´ê¸° (Sheets ì—…ë°ì´íŠ¸ ì—†ìŒ)
    python scripts/apply_cross_query_merge.py --dry_run

    # ì‹¤ì œ ì ìš©
    python scripts/apply_cross_query_merge.py
"""

import os
import sys
import time
import argparse
from pathlib import Path

import pandas as pd
from dotenv import load_dotenv

sys.path.insert(0, str(Path(__file__).parent.parent))
load_dotenv()

TARGET_COLS = ["cluster_id", "source", "cluster_summary"]


def load_total_result(spreadsheet) -> tuple:
    """total_result ì›Œí¬ì‹œíŠ¸ â†’ (df, worksheet, headers, link_to_row)"""
    ws = spreadsheet.worksheet("total_result")
    all_values = ws.get_all_values()
    if not all_values:
        raise RuntimeError("total_result ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŒ")

    headers = all_values[0]
    rows = all_values[1:]
    df = pd.DataFrame(rows, columns=headers)

    # Sheets í–‰ ë²ˆí˜¸ ë§¤í•‘: link â†’ ì‹œíŠ¸ í–‰ ë²ˆí˜¸ (í—¤ë”=1, ë°ì´í„° ì‹œì‘=2)
    link_col = "link"
    if link_col not in df.columns:
        raise RuntimeError("total_resultì— link ì»¬ëŸ¼ ì—†ìŒ")

    link_to_sheet_row = {}
    for df_idx, row_values in enumerate(rows):
        link_val = row_values[headers.index(link_col)] if link_col in headers else ""
        if link_val:
            link_to_sheet_row[link_val] = df_idx + 2  # +2: í—¤ë”í–‰ + 0-base ë³´ì •

    return df, ws, headers, link_to_sheet_row


def run(dry_run: bool):
    from src.modules.export.sheets import connect_sheets
    from src.modules.analysis.source_verifier import merge_cross_query_clusters

    creds_path = os.getenv("GOOGLE_SHEETS_CREDENTIALS_PATH", "service-account.json")
    sheet_id = os.getenv("GOOGLE_SHEET_ID")
    openai_key = os.getenv("OPENAI_API_KEY")

    if not os.path.exists(creds_path) or not sheet_id:
        print("âŒ GOOGLE_SHEETS_CREDENTIALS_PATH ë˜ëŠ” GOOGLE_SHEET_ID ë¯¸ì„¤ì •")
        return

    # â”€â”€ 1. Sheets ì—°ê²° + ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸ“Š Google Sheets ì—°ê²° ì¤‘...")
    sp = connect_sheets(creds_path, sheet_id)
    df, ws, headers, link_to_sheet_row = load_total_result(sp)
    print(f"  âœ… total_result: {len(df)}í–‰ ë¡œë“œ")

    # í•„ìˆ˜ ì»¬ëŸ¼ ë³´ì¥
    for col in ["cluster_id", "source", "cluster_summary", "query", "title",
                "description", "pub_datetime", "media_domain", "news_category"]:
        if col not in df.columns:
            df[col] = ""

    # â”€â”€ 2. ë³€ê²½ ì „ ìŠ¤ëƒ…ìƒ· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    before = df[TARGET_COLS].copy()

    # â”€â”€ 3. ìƒˆ ì„ê³„ê°’ìœ¼ë¡œ merge_cross_query_clusters ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ”€ ìƒˆ ì„ê³„ê°’ìœ¼ë¡œ Cross-query ë³‘í•© ì‹¤í–‰ ì¤‘...")
    df_updated, stats = merge_cross_query_clusters(df, openai_key=openai_key)

    print(f"\n  ë³‘í•© ê·¸ë£¹: {stats['sv_cross_merged_groups']}ê°œ")
    print(f"  ë³‘í•© ê¸°ì‚¬: {stats['sv_cross_merged_articles']}ê°œ")

    # â”€â”€ 4. ë³€ê²½ëœ í–‰ ì°¾ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    after = df_updated[TARGET_COLS]
    changed_mask = (before != after).any(axis=1)
    changed_df = df_updated[changed_mask].copy()
    changed_before = before[changed_mask].copy()

    print(f"\n  ë³€ê²½ëœ í–‰: {len(changed_df)}ê°œ")

    if len(changed_df) == 0:
        print("  â„¹ï¸  ë³€ê²½ì‚¬í•­ ì—†ìŒ. Sheets ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš”.")
        return

    # â”€â”€ 5. ë³€ê²½ì‚¬í•­ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "â”€" * 80)
    print("ë³€ê²½ ë‚´ì—­:")
    print("â”€" * 80)

    for df_idx in changed_df.index:
        row_before = changed_before.loc[df_idx]
        row_after = changed_df.loc[df_idx]
        title = str(df_updated.at[df_idx, "title"])[:60]
        link = str(df_updated.at[df_idx, "link"]) if "link" in df_updated.columns else ""
        sheet_row = link_to_sheet_row.get(link, "?")

        print(f"\n  [í–‰ {sheet_row}] {title}")
        for col in TARGET_COLS:
            if str(row_before[col]) != str(row_after[col]):
                print(f"    {col}: '{row_before[col]}' â†’ '{row_after[col]}'")

    if dry_run:
        print(f"\n{'â”€'*80}")
        print("  [DRY RUN] Sheets ì—…ë°ì´íŠ¸ ìƒëµ. --dry_run ì—†ì´ ì‹¤í–‰í•˜ë©´ ì ìš©ë©ë‹ˆë‹¤.")
        return

    # â”€â”€ 6. Sheets batch ì—…ë°ì´íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\n{'â”€'*80}")
    print("â˜ï¸  Sheets ì—…ë°ì´íŠ¸ ì¤‘...")

    # ì»¬ëŸ¼ â†’ Sheets ì—´ ë²ˆí˜¸ ë§¤í•‘
    col_indices = {}
    for col in TARGET_COLS:
        if col in headers:
            col_indices[col] = headers.index(col)
        else:
            # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ í—¤ë” ëì— ì¶”ê°€
            ws.add_cols(1)
            headers.append(col)
            col_indices[col] = len(headers) - 1
            ws.update_cell(1, col_indices[col] + 1, col)
            print(f"  â„¹ï¸  '{col}' ì»¬ëŸ¼ ì‹ ê·œ ì¶”ê°€ (í—¤ë” í–‰)")

    # batch_data: [{range: "A2", values: [[val]]}, ...]
    batch_data = []
    for df_idx in changed_df.index:
        link = str(df_updated.at[df_idx, "link"]) if "link" in df_updated.columns else ""
        sheet_row = link_to_sheet_row.get(link)
        if sheet_row is None:
            print(f"  âš ï¸  í–‰ ìœ„ì¹˜ ì°¾ê¸° ì‹¤íŒ¨: {link[:60]}")
            continue

        for col in TARGET_COLS:
            if str(before.at[df_idx, col]) != str(after.at[df_idx, col]):
                col_num = col_indices[col] + 1  # 1-based
                cell_addr = f"{_col_letter(col_num)}{sheet_row}"
                new_val = str(df_updated.at[df_idx, col]) if pd.notna(df_updated.at[df_idx, col]) else ""
                batch_data.append({
                    "range": cell_addr,
                    "values": [[new_val]]
                })

    if not batch_data:
        print("  â„¹ï¸  ì—…ë°ì´íŠ¸í•  ì…€ ì—†ìŒ")
        return

    # gspread batch_update (ìµœëŒ€ 500ì…€ ë‹¨ìœ„)
    BATCH_SIZE = 500
    total_cells = len(batch_data)
    updated = 0
    for i in range(0, total_cells, BATCH_SIZE):
        batch = batch_data[i:i + BATCH_SIZE]
        ws.batch_update(batch, value_input_option="RAW")
        updated += len(batch)
        print(f"  ì—…ë°ì´íŠ¸: {updated}/{total_cells}ì…€")
        if i + BATCH_SIZE < total_cells:
            time.sleep(1.0)

    print(f"\nâœ… Sheets ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(changed_df)}í–‰ / {total_cells}ì…€")


def _col_letter(n: int) -> str:
    """1-based ì»¬ëŸ¼ ë²ˆí˜¸ â†’ A, B, ..., Z, AA, ..."""
    result = ""
    while n > 0:
        n -= 1
        result = chr(65 + n % 26) + result
        n //= 26
    return result


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ìƒˆ Cross-query ì„ê³„ê°’ Sheets ì ìš©")
    parser.add_argument("--dry_run", action="store_true", help="ë³€ê²½ì‚¬í•­ ë¯¸ë¦¬ë³´ê¸° (Sheets ì—…ë°ì´íŠ¸ ì—†ìŒ)")
    args = parser.parse_args()
    run(dry_run=args.dry_run)
