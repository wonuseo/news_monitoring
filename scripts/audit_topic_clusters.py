#!/usr/bin/env python3
"""
audit_topic_clusters.py - Topic í´ëŸ¬ìŠ¤í„° ìë™ ê²€ì¦

ëª¨ë“  topic group (_t í´ëŸ¬ìŠ¤í„°)ì„ LLMìœ¼ë¡œ ì¬ê²€ì¦í•˜ì—¬ ì˜ëª» ë¬¶ì¸ í´ëŸ¬ìŠ¤í„°ë¥¼ ìë™ íƒì§€í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
  python audit_topic_clusters.py                    # ê²€ì¦ë§Œ (ë¦¬í¬íŠ¸ ì¶œë ¥)
  python audit_topic_clusters.py --auto_fix          # ê²€ì¦ + ìë™ í•´ì²´
  python audit_topic_clusters.py --min_confidence 0.7  # ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •
"""

import os
import argparse
import pandas as pd
from dotenv import load_dotenv
from typing import Dict, List, Tuple

from src.modules.export.sheets import connect_sheets, sync_to_sheets
from src.modules.analysis.llm_engine import (
    load_source_verifier_prompts,
    render_prompt,
    call_openai_structured,
)
from src.utils.openai_client import load_api_models


def _get_sv_model() -> str:
    """source_verification ëª¨ë¸ ë¡œë“œ."""
    api_models = load_api_models()
    return api_models.get("source_verification", "gpt-4o-mini")


def verify_cluster_coherence(
    cluster_df: pd.DataFrame,
    cluster_id: str,
    openai_key: str,
) -> Dict:
    """
    LLMìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° ì¼ê´€ì„± ê²€ì¦ (í´ëŸ¬ìŠ¤í„° ë‚´ ëª¨ë“  ê¸°ì‚¬ê°€ ê°™ì€ ì£¼ì œì¸ì§€).

    ì „ëµ: ëŒ€í‘œ ê¸°ì‚¬(ì²« ë²ˆì§¸)ì™€ ë‚˜ë¨¸ì§€ ê¸°ì‚¬ë“¤ì„ ê°ê° ë¹„êµí•˜ì—¬
    ë‹¤ë¥¸ ì£¼ì œë¡œ íŒë‹¨ë˜ëŠ” ê¸°ì‚¬ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í´ëŸ¬ìŠ¤í„°ë¥¼ í•´ì²´ ê¶Œì¥.

    Args:
        cluster_df: í´ëŸ¬ìŠ¤í„° ë‚´ ê¸°ì‚¬ DataFrame
        cluster_id: í´ëŸ¬ìŠ¤í„° ID
        openai_key: OpenAI API í‚¤

    Returns:
        {
            "cluster_id": str,
            "coherent": bool,  # ì¼ê´€ì„± ìˆëŠ” í´ëŸ¬ìŠ¤í„°ì¸ê°€
            "article_count": int,
            "mismatches": List[Dict],  # ë‹¤ë¥¸ ì£¼ì œë¡œ íŒë‹¨ëœ ê¸°ì‚¬ë“¤
            "error": str or None,
        }
    """
    result = {
        "cluster_id": cluster_id,
        "coherent": True,
        "article_count": len(cluster_df),
        "mismatches": [],
        "error": None,
    }

    if len(cluster_df) < 2:
        result["coherent"] = True
        return result

    # ëŒ€í‘œ ê¸°ì‚¬ (ì²« ë²ˆì§¸)
    representative = cluster_df.iloc[0]
    rep_summary = str(representative.get("news_keyword_summary", ""))
    rep_title = str(representative.get("title", ""))

    # ë‚˜ë¨¸ì§€ ê¸°ì‚¬ë“¤ê³¼ ë¹„êµ
    prompts = load_source_verifier_prompts()
    ts_config = prompts.get("topic_similarity", {})

    system_prompt = ts_config.get("system", "")
    user_template = ts_config.get("user_prompt_template", "")
    response_schema = ts_config.get("response_schema", {})

    if not system_prompt or not user_template:
        result["error"] = "topic_similarity í”„ë¡¬í”„íŠ¸ ì—†ìŒ"
        result["coherent"] = False
        return result

    model = _get_sv_model()

    for idx, row in cluster_df.iloc[1:].iterrows():
        article_summary = str(row.get("news_keyword_summary", ""))
        article_title = str(row.get("title", ""))

        if not article_summary or not rep_summary:
            continue

        # Context êµ¬ì„±
        context_a = f"ì œëª©: {rep_title}\nìš”ì•½: {rep_summary}"
        context_b = f"ì œëª©: {article_title}\nìš”ì•½: {article_summary}"

        context = {
            "context_a": context_a,
            "context_b": context_b,
        }

        user_prompt = render_prompt(user_template, context)

        try:
            llm_result = call_openai_structured(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                response_schema=response_schema,
                openai_key=openai_key,
                model=model,
                label="í´ëŸ¬ìŠ¤í„°ê²€ì¦",
                schema_name="topic_similarity_result",
            )

            if llm_result and "same_topic" in llm_result:
                same_topic = llm_result["same_topic"]
                reason = llm_result.get("reason", "")

                if not same_topic:
                    # ë‹¤ë¥¸ ì£¼ì œë¡œ íŒë‹¨ë¨
                    result["coherent"] = False
                    result["mismatches"].append({
                        "title": article_title,
                        "reason": reason,
                    })

        except Exception as e:
            result["error"] = f"LLM ê²€ì¦ ì‹¤íŒ¨: {e}"
            result["coherent"] = False
            return result

    return result


def audit_all_topic_clusters(
    df: pd.DataFrame,
    openai_key: str,
    min_size: int = 2,
) -> Tuple[List[Dict], List[str]]:
    """
    ëª¨ë“  topic í´ëŸ¬ìŠ¤í„°ë¥¼ ê²€ì¦í•˜ì—¬ ì˜ëª» ë¬¶ì¸ ê²ƒì„ íƒì§€.

    Args:
        df: ì „ì²´ ë°ì´í„° DataFrame
        openai_key: OpenAI API í‚¤
        min_size: ê²€ì¦ ëŒ€ìƒ ìµœì†Œ í´ëŸ¬ìŠ¤í„° í¬ê¸° (ê¸°ë³¸ 2)

    Returns:
        (audit_results, problematic_cluster_ids)
    """
    # _të¡œ ì‹œì‘í•˜ëŠ” cluster_idë§Œ í•„í„°ë§
    if "cluster_id" not in df.columns:
        print("âš ï¸  cluster_id ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return [], []

    topic_mask = df["cluster_id"].str.contains("_t", na=False)
    df_topics = df[topic_mask].copy()

    if len(df_topics) == 0:
        print("â„¹ï¸  ê²€ì¦í•  topic í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return [], []

    # cluster_idë³„ ê·¸ë£¹í•‘
    cluster_groups = df_topics.groupby("cluster_id", dropna=False)
    print(f"\nğŸ“Š ì´ {len(cluster_groups)}ê°œ topic í´ëŸ¬ìŠ¤í„° ê²€ì¦ ì‹œì‘...")

    audit_results = []
    problematic_ids = []

    for cluster_id, cluster_df in cluster_groups:
        if len(cluster_df) < min_size:
            continue

        print(f"  ğŸ” ê²€ì¦ ì¤‘: {cluster_id} ({len(cluster_df)}ê°œ ê¸°ì‚¬)...", end=" ")

        result = verify_cluster_coherence(cluster_df, cluster_id, openai_key)
        audit_results.append(result)

        if not result["coherent"]:
            problematic_ids.append(cluster_id)
            print(f"âŒ ë¬¸ì œ ë°œê²¬ ({len(result['mismatches'])}ê°œ ë¶ˆì¼ì¹˜)")
        else:
            print("âœ… ì •ìƒ")

    return audit_results, problematic_ids


def generate_audit_report(audit_results: List[Dict], df: pd.DataFrame):
    """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±."""
    print("\n" + "=" * 100)
    print("ğŸ“‹ Topic í´ëŸ¬ìŠ¤í„° ê²€ì¦ ë¦¬í¬íŠ¸")
    print("=" * 100)

    total = len(audit_results)
    coherent_count = sum(1 for r in audit_results if r["coherent"])
    problematic_count = total - coherent_count

    print(f"\nì´ ê²€ì¦ í´ëŸ¬ìŠ¤í„°: {total}ê°œ")
    print(f"  âœ… ì •ìƒ: {coherent_count}ê°œ")
    print(f"  âŒ ë¬¸ì œ ë°œê²¬: {problematic_count}ê°œ")

    if problematic_count > 0:
        print(f"\n{'=' * 100}")
        print("âŒ ë¬¸ì œê°€ ìˆëŠ” í´ëŸ¬ìŠ¤í„° ìƒì„¸:")
        print(f"{'=' * 100}")

        for result in audit_results:
            if not result["coherent"]:
                cluster_id = result["cluster_id"]
                cluster_df = df[df["cluster_id"] == cluster_id]

                print(f"\n[{cluster_id}] - {result['article_count']}ê°œ ê¸°ì‚¬")
                print(f"  ë¶ˆì¼ì¹˜: {len(result['mismatches'])}ê°œ")

                # ê¸°ì‚¬ ì œëª© ì¶œë ¥
                print(f"\n  ê¸°ì‚¬ ëª©ë¡:")
                for idx, row in cluster_df.iterrows():
                    print(f"    - {row['title'][:80]}")

                # ë¶ˆì¼ì¹˜ ì´ìœ 
                if result["mismatches"]:
                    print(f"\n  ë¶ˆì¼ì¹˜ ê¸°ì‚¬:")
                    for mismatch in result["mismatches"]:
                        print(f"    âŒ {mismatch['title'][:80]}")
                        print(f"       ì´ìœ : {mismatch['reason']}")

                if result.get("error"):
                    print(f"  âš ï¸  ì—ëŸ¬: {result['error']}")

    print(f"\n{'=' * 100}\n")


def fix_problematic_clusters(df: pd.DataFrame, cluster_ids: List[str]) -> pd.DataFrame:
    """
    ë¬¸ì œê°€ ìˆëŠ” í´ëŸ¬ìŠ¤í„°ë¥¼ í•´ì²´ (ì¼ë°˜ê¸°ì‚¬ë¡œ ë˜ëŒë¦¼).

    Args:
        df: ì „ì²´ ë°ì´í„° DataFrame
        cluster_ids: í•´ì²´í•  cluster_id ë¦¬ìŠ¤íŠ¸

    Returns:
        ìˆ˜ì •ëœ DataFrame
    """
    df = df.copy()

    for cluster_id in cluster_ids:
        mask = df["cluster_id"] == cluster_id
        affected_count = mask.sum()

        if affected_count > 0:
            print(f"  ğŸ”§ '{cluster_id}' í´ëŸ¬ìŠ¤í„° í•´ì²´ ({affected_count}ê°œ ê¸°ì‚¬)")
            df.loc[mask, "cluster_id"] = ""
            df.loc[mask, "source"] = "ì¼ë°˜ê¸°ì‚¬"
            df.loc[mask, "press_release_group"] = ""

    return df


def main():
    parser = argparse.ArgumentParser(description="Topic í´ëŸ¬ìŠ¤í„° ìë™ ê²€ì¦")
    parser.add_argument("--auto_fix", action="store_true",
                        help="ë¬¸ì œ í´ëŸ¬ìŠ¤í„° ìë™ í•´ì²´ (ì—†ìœ¼ë©´ ë¦¬í¬íŠ¸ë§Œ ì¶œë ¥)")
    parser.add_argument("--min_size", type=int, default=2,
                        help="ê²€ì¦ ëŒ€ìƒ ìµœì†Œ í´ëŸ¬ìŠ¤í„° í¬ê¸° (ê¸°ë³¸: 2)")
    parser.add_argument("--sheets_id", type=str, default=None,
                        help="Google Sheets ID (.env ëŒ€ì‹  ì‚¬ìš©)")
    args = parser.parse_args()

    load_dotenv()

    # OpenAI API í‚¤ í™•ì¸
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # Google Sheets ì—°ê²°
    creds_path = os.getenv("GOOGLE_SHEETS_CREDENTIALS_PATH", "service-account.json")
    sheet_id = args.sheets_id or os.getenv("GOOGLE_SHEET_ID")

    if not os.path.exists(creds_path) or not sheet_id:
        print("âŒ Google Sheets ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("  .envì— GOOGLE_SHEETS_CREDENTIALS_PATH, GOOGLE_SHEET_IDë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return

    spreadsheet = connect_sheets(creds_path, sheet_id)
    if not spreadsheet:
        return

    # total_result ë¡œë“œ
    print("\nğŸ“‚ ì´ ê²°ê³¼ ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        worksheet = spreadsheet.worksheet("total_result")
        records = worksheet.get_all_records()
    except Exception as e:
        print(f"âŒ total_result ì‹œíŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    if not records:
        print("âŒ total_result ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return

    df = pd.DataFrame(records)
    print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ê¸°ì‚¬")

    # ëª¨ë“  topic í´ëŸ¬ìŠ¤í„° ê²€ì¦
    audit_results, problematic_ids = audit_all_topic_clusters(
        df, openai_key, min_size=args.min_size
    )

    # ë¦¬í¬íŠ¸ ìƒì„±
    generate_audit_report(audit_results, df)

    # ìë™ ìˆ˜ì •
    if args.auto_fix and problematic_ids:
        print(f"\nğŸ”§ ìë™ ìˆ˜ì • ëª¨ë“œ: {len(problematic_ids)}ê°œ í´ëŸ¬ìŠ¤í„° í•´ì²´ ì¤‘...")
        df_fixed = fix_problematic_clusters(df, problematic_ids)

        print(f"\në³€ê²½ í›„ source ë¶„í¬:")
        print(df_fixed["source"].value_counts().to_string())

        print("\nğŸ“¤ Google Sheets ì—…ë°ì´íŠ¸ ì¤‘...")
        result = sync_to_sheets(
            df_fixed, spreadsheet, "total_result",
            force_update_existing=True,
        )
        print(f"âœ… ì™„ë£Œ: ì¶”ê°€ {result.get('added', 0)}ê°œ, "
              f"ì—…ë°ì´íŠ¸ {result.get('updated', 0)}ê°œ, "
              f"ê±´ë„ˆëœ€ {result.get('skipped', 0)}ê°œ")

        # ë¡œì»¬ CSV ë°±ì—…ë„ ì—…ë°ì´íŠ¸
        csv_path = "../data/result.csv"
        if os.path.exists(csv_path):
            print(f"\nğŸ“ ë¡œì»¬ CSV ë°±ì—… ì—…ë°ì´íŠ¸: {csv_path}")
            df_csv = pd.read_csv(csv_path, encoding="utf-8-sig")

            update_cols = ["link", "source", "cluster_id", "press_release_group"]
            df_updates = df_fixed[update_cols].copy()

            df_csv = df_csv.drop(columns=["source", "cluster_id", "press_release_group"], errors="ignore")
            df_csv = df_csv.merge(df_updates, on="link", how="left")
            df_csv.to_csv(csv_path, index=False, encoding="utf-8-sig")
            print(f"âœ… CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(df_csv)}ê°œ ê¸°ì‚¬")

        print("\nâœ… ìë™ ìˆ˜ì • ì™„ë£Œ!")

    elif problematic_ids:
        print(f"\nğŸ’¡ ìˆ˜ì • ê¶Œì¥: {len(problematic_ids)}ê°œ í´ëŸ¬ìŠ¤í„°")
        print(f"\nìë™ ìˆ˜ì •í•˜ë ¤ë©´ --auto_fix í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:")
        print(f"  python audit_topic_clusters.py --auto_fix")

    else:
        print("\nâœ… ëª¨ë“  topic í´ëŸ¬ìŠ¤í„°ê°€ ì •ìƒì…ë‹ˆë‹¤!")


if __name__ == "__main__":
    main()
