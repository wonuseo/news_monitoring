#!/usr/bin/env python3
"""One-time Google Sheets cleanup: drop pre-2026-02-01 articles."""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

import argparse
import os
import time
from datetime import datetime, timezone
from typing import Iterable, List, Optional

from dateutil import parser as date_parser
from dotenv import load_dotenv

from src.modules.export.sheets import connect_sheets


DATE_COLUMN_PRIORITY = [
    "pub_datetime",
    "date_only",
    "pubDate",
    "pub_date",
    "published_at",
    "date",
]


def parse_cutoff(value: str) -> datetime:
    """Convert user cutoff (e.g., 2026-02-01) to timezone-aware UTC."""
    parsed = date_parser.parse(value)
    if parsed.tzinfo is None:
        parsed = parsed.replace(tzinfo=timezone.utc)
    return parsed.astimezone(timezone.utc)


def parse_sheet_date(value) -> Optional[datetime]:
    """Try to parse a date string from the sheet and return UTC."""
    if value is None:
        return None

    if isinstance(value, (int, float)):
        value = str(value)

    try:
        parsed = date_parser.parse(str(value))
    except (ValueError, OverflowError):
        return None

    if parsed.tzinfo is None:
        parsed = parsed.replace(tzinfo=timezone.utc)
    return parsed.astimezone(timezone.utc)


def find_date_column(headers: Iterable[str]) -> Optional[str]:
    """Return the header name that best matches a publication column."""
    normalized = {header.lower(): header for header in headers if isinstance(header, str)}
    for candidate in DATE_COLUMN_PRIORITY:
        candidate_lower = candidate.lower()
        if candidate_lower in normalized:
            return normalized[candidate_lower]
    return None


def prune_worksheet(worksheet, cutoff: datetime, dry_run: bool) -> int:
    """Remove rows older than cutoff; returns number of deleted rows."""
    headers = worksheet.row_values(1)
    if not headers:
        print(f"  âš ï¸  '{worksheet.title}'ì— í—¤ë”ê°€ ì—†ì–´ ê±´ë„ˆëœ€.")
        return 0

    date_column = find_date_column(headers)
    if not date_column:
        header_names = ", ".join(headers[:5])
        print(
            f"  âš ï¸  '{worksheet.title}'ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (ì˜ˆì‹œ: {header_names})."
        )
        return 0

    records = worksheet.get_all_records()
    if not records:
        print(f"  â„¹ï¸  '{worksheet.title}'ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    rows_to_delete: List[int] = []
    skipped = 0
    for row_idx, record in enumerate(records, start=2):
        published_value = record.get(date_column, "")
        published_dt = parse_sheet_date(published_value)
        if not published_dt:
            skipped += 1
            continue
        if published_dt < cutoff:
            rows_to_delete.append(row_idx)

    if not rows_to_delete:
        print(f"  âœ… '{worksheet.title}'ì— ì‚­ì œ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤ (í•´ë‹¹ ë‚ ì§œ ì´ì „ ì—†ìŒ).")
        return 0

    deleted_count = 0
    if dry_run:
        print(
            f"  ğŸ§ª '{worksheet.title}'ì—ì„œ ì‚­ì œ ì˜ˆì • í–‰: {len(rows_to_delete)} (ì ˆì‚­ ë‚ ì§œ: {cutoff.date()})"
        )
        return len(rows_to_delete)

    print(
        f"  ğŸ§¹ '{worksheet.title}'ì—ì„œ {len(rows_to_delete)}ê°œ í–‰ ì‚­ì œ (ê¸°ì¤€: {cutoff.date()})"
    )
    for row_idx in reversed(rows_to_delete):
        try:
            worksheet.delete_rows(row_idx)
            deleted_count += 1
            time.sleep(0.2)
        except Exception as exc:
            print(f"    âš ï¸ ì‚­ì œ ì‹¤íŒ¨: {worksheet.title} row {row_idx} -> {exc}")
    print(f"  âœ… '{worksheet.title}': ì´ {deleted_count}ê°œ í–‰ ì‚­ì œ")
    if skipped:
        print(f"    â„¹ï¸  {skipped}ê°œ í–‰ì˜ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ (ë¬´ì‹œë¨)")
    return deleted_count


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Google Sheetsì—ì„œ 2026-02-01 ì´ì „ ê¸°ì‚¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."
    )
    parser.add_argument(
        "--cutoff",
        default="2026-02-01",
        help="ì‚­ì œ ê¸°ì¤€ ë‚ ì§œ (ISO, ê¸°ë³¸: 2026-02-01).",
    )
    parser.add_argument(
        "--worksheets",
        default="total_result",
        help="ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì›Œí¬ì‹œíŠ¸ ëª©ë¡ (ê¸°ë³¸: total_result).",
    )
    parser.add_argument(
        "--credentials",
        default=None,
        help="ì„œë¹„ìŠ¤ ê³„ì • JSON ê²½ë¡œ (.envì˜ GOOGLE_SHEETS_CREDENTIALS_PATHë¥¼ ê±´ë„ˆëœ€)",
    )
    parser.add_argument(
        "--sheet-id",
        default=None,
        help="Google Sheets ID (.envì˜ GOOGLE_SHEET_ID ëŒ€ì‹  ì‚¬ìš©)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‚­ì œ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.",
    )

    args = parser.parse_args()
    load_dotenv()

    creds_path = (
        args.credentials
        or os.getenv("GOOGLE_SHEETS_CREDENTIALS_PATH")
        or "service-account.json"
    )
    sheet_id = args.sheet_id or os.getenv("GOOGLE_SHEET_ID")
    if not sheet_id:
        parser.error("Google Sheets ID (.env ë˜ëŠ” --sheet-id) ê°’ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    cutoff = parse_cutoff(args.cutoff)
    worksheet_names = [name.strip() for name in args.worksheets.split(",") if name.strip()]

    print("Google Sheets ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰")
    print(f"  - ê¸°ì¤€ ë‚ ì§œ: {cutoff.isoformat()}")
    print(f"  - ì›Œí¬ì‹œíŠ¸: {', '.join(worksheet_names)}")
    print("  - dry run:" + (" ì˜ˆ" if args.dry_run else " ì•„ë‹ˆì˜¤"))

    spreadsheet = connect_sheets(creds_path, sheet_id)
    if not spreadsheet:
        raise SystemExit(1)

    total_deleted = 0
    for sheet_name in worksheet_names:
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
        except Exception as exc:
            print(f"  âš ï¸  ì›Œí¬ì‹œíŠ¸ '{sheet_name}'ì„(ë¥¼) ì—´ ìˆ˜ ì—†ìŒ: {exc}")
            continue
        deleted = prune_worksheet(worksheet, cutoff, args.dry_run)
        total_deleted += deleted

    if args.dry_run:
        print(f"ì „ì²´ ì˜ˆìƒ ì‚­ì œ: {total_deleted}ê°œ")
    else:
        print(f"ì „ì²´ ì‚­ì œ ì™„ë£Œ: {total_deleted}ê°œ")


if __name__ == "__main__":
    main()
